{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41476c66",
   "metadata": {},
   "source": [
    "# TF-IDF Text Classification with N-grams and Naive Bayes\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **TF-IDF Vectorization with N-grams** using scikit-learn\n",
    "2. **Naive Bayes Classification** for Tamil news articles\n",
    "3. **Model Evaluation** with comprehensive metrics\n",
    "\n",
    "**Features:**\n",
    "- N-gram TF-IDF features (unigrams + bigrams, max 10,000 features)\n",
    "- Document frequency filtering (min_df=3, max_df=0.8)\n",
    "- Multinomial Naive Bayes classifier\n",
    "- Dual task: Category classification and Sentiment classification\n",
    "- Comparison with unigram-only approach\n",
    "\n",
    "**Dataset:** Tamil news articles with categories and processed text\n",
    "\n",
    "**N-gram Benefits:**\n",
    "- Captures word sequences (e.g., \"இலங்கை அரசு\")\n",
    "- Better context understanding\n",
    "- More discriminative features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09efb73e",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c87caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"N-gram tokenization enabled ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419105a",
   "metadata": {},
   "source": [
    "## 2. Load the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf68dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data from preprocessing notebook\n",
    "df = pd.read_csv('output/processed_data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data distribution\n",
    "print(\"Category distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nTotal samples: {len(df)}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745d8d8",
   "metadata": {},
   "source": [
    "## 3. Prepare Text Data for TF-IDF\n",
    "\n",
    "We'll use the `cleaned_title` column which contains preprocessed Tamil text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the text column and target variable\n",
    "documents = df['cleaned_title'].fillna('').tolist()\n",
    "labels = df['category'].tolist()\n",
    "\n",
    "print(f\"Total documents: {len(documents)}\")\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "print(f\"\\nSample document: {documents[0]}\")\n",
    "print(f\"Sample label: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e666bc5",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Vectorization with N-grams\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** converts text into numerical features:\n",
    "- **TF**: Measures how frequently a term appears in a document\n",
    "- **IDF**: Measures how important a term is across all documents\n",
    "- **TF-IDF**: Combines both to get weighted features\n",
    "\n",
    "**N-gram Enhancement:**\n",
    "- **Unigrams (1-gram)**: Single words (\"இலங்கை\", \"அரசு\")\n",
    "- **Bigrams (2-gram)**: Word pairs (\"இலங்கை அரசு\")\n",
    "- **ngram_range=(1,2)**: Combines both unigrams and bigrams\n",
    "\n",
    "**Parameters:**\n",
    "- `max_features=10000`: Keep only top 10,000 most important n-grams\n",
    "- `min_df=3`: Ignore n-grams appearing in less than 3 documents\n",
    "- `max_df=0.8`: Ignore n-grams appearing in more than 80% of documents\n",
    "- `ngram_range=(1,2)`: Use unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer with n-grams\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2),  # Unigrams + Bigrams\n",
    "    token_pattern=r'\\S+',  # Split on whitespace\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# Fit and transform the documents\n",
    "print(\"Creating TF-IDF matrix with n-grams...\")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "print(f\"\\n✓ TF-IDF Matrix created: {tfidf_matrix.shape}\")\n",
    "print(f\"  Documents: {tfidf_matrix.shape[0]:,}\")\n",
    "print(f\"  N-gram Features: {tfidf_matrix.shape[1]:,}\")\n",
    "print(f\"  Matrix type: {type(tfidf_matrix)}\")\n",
    "print(f\"  Data type: {tfidf_matrix.dtype}\")\n",
    "print(f\"  Sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b879847",
   "metadata": {},
   "source": [
    "## 5. N-gram Feature Examples\n",
    "\n",
    "Let's look at some example features to understand what n-grams capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a26b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names (n-grams)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Total features: {len(feature_names):,}\")\n",
    "print(f\"\\nSample unigrams (single words):\")\n",
    "unigrams = [f for f in feature_names[:50] if ' ' not in f]\n",
    "print(unigrams[:10])\n",
    "\n",
    "print(f\"\\nSample bigrams (word pairs):\")\n",
    "bigrams = [f for f in feature_names if ' ' in f]\n",
    "print(bigrams[:10])\n",
    "\n",
    "print(f\"\\nFeature type breakdown:\")\n",
    "n_unigrams = sum(1 for f in feature_names if ' ' not in f)\n",
    "n_bigrams = sum(1 for f in feature_names if ' ' in f)\n",
    "print(f\"  Unigrams: {n_unigrams:,} ({n_unigrams/len(feature_names)*100:.1f}%)\")\n",
    "print(f\"  Bigrams: {n_bigrams:,} ({n_bigrams/len(feature_names)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a0288",
   "metadata": {},
   "source": [
    "## 6. Prepare Data for Machine Learning\n",
    "\n",
    "Split the data into training (80%) and testing (20%) sets with stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d85f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TF-IDF matrix as features\n",
    "X = tfidf_matrix\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split data: 80% train, 20% test with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"N-gram feature dimension: {X_train.shape[1]}\")\n",
    "print(f\"\\nTraining set label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set label distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d03997",
   "metadata": {},
   "source": [
    "## 7. Train Naive Bayes Model\n",
    "\n",
    "**Naive Bayes** is a probabilistic classifier based on Bayes' theorem:\n",
    "- **Fast training and prediction**\n",
    "- **Works well with text data**\n",
    "- **Assumes independence between features**\n",
    "- **MultinomialNB** is designed for discrete features like word counts/TF-IDF\n",
    "- **Works effectively with n-gram features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Naive Bayes model\n",
    "print(\"Training Naive Bayes model with n-gram features...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_train_pred = nb_model.predict(X_train)\n",
    "nb_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "print(\"✓ Naive Bayes training completed\")\n",
    "print(f\"  Classes: {nb_model.classes_}\")\n",
    "print(f\"  Number of classes: {len(nb_model.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912177c7",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n",
    "\n",
    "Evaluate the model using multiple metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: How many selected items are relevant\n",
    "- **Recall**: How many relevant items are selected\n",
    "- **F1-Score**: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with multiple metrics.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} - {dataset_name} Set\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "nb_train_metrics = evaluate_model(y_train, nb_train_pred, \"Naive Bayes (N-gram)\", \"Training\")\n",
    "nb_test_metrics = evaluate_model(y_test, nb_test_pred, \"Naive Bayes (N-gram)\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60740f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, nb_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20176118",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix\n",
    "\n",
    "Visualize the confusion matrix to see which categories are confused with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da66887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "nb_cm = confusion_matrix(y_test, nb_test_pred)\n",
    "classes = sorted(list(set(y_test)))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(nb_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes, cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Naive Bayes with N-grams (Category)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be498182",
   "metadata": {},
   "source": [
    "## 10. Save Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "with open('models/category_naive_bayes_tfidf_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_model, f)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open('models/category_tfidf_vectorizer_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# Save evaluation report\n",
    "import json\n",
    "\n",
    "report = {\n",
    "    'model': 'MultinomialNB',\n",
    "    'vectorizer': 'TfidfVectorizer',\n",
    "    'ngram_range': '(1,2)',\n",
    "    'max_features': 10000,\n",
    "    'train_metrics': nb_train_metrics,\n",
    "    'test_metrics': nb_test_metrics,\n",
    "    'classification_report': classification_report(y_test, nb_test_pred, output_dict=True, zero_division=0)\n",
    "}\n",
    "\n",
    "with open('reports/category_naive_bayes_tfidf_ngram_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"✓ Model saved to models/category_naive_bayes_tfidf_ngram.pkl\")\n",
    "print(\"✓ Vectorizer saved to models/category_tfidf_vectorizer_ngram.pkl\")\n",
    "print(\"✓ Evaluation report saved to reports/category_naive_bayes_tfidf_ngram_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b6379",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SENTIMENT CLASSIFICATION WITH N-GRAMS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829b45b",
   "metadata": {},
   "source": [
    "## 11. Load Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe449ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment data\n",
    "df_sentiment = pd.read_csv('output/processed_sentiment_data.csv')\n",
    "\n",
    "print(f\"Sentiment Dataset shape: {df_sentiment.shape}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df_sentiment['sentiment'].value_counts())\n",
    "\n",
    "sentiment_documents = df_sentiment['tokenized_title'].fillna('').tolist()\n",
    "sentiment_labels = df_sentiment['sentiment'].tolist()\n",
    "\n",
    "print(f\"\\nTotal sentiment documents: {len(sentiment_documents)}\")\n",
    "print(f\"Sample: {sentiment_documents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0525223",
   "metadata": {},
   "source": [
    "## 12. TF-IDF Vectorization for Sentiment with N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cec557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer for sentiment with n-grams\n",
    "sentiment_tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2),  # Unigrams + Bigrams\n",
    "    token_pattern=r'\\S+',\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# Fit and transform sentiment documents\n",
    "print(\"Creating TF-IDF matrix for sentiment with n-grams...\")\n",
    "sentiment_tfidf_matrix = sentiment_tfidf_vectorizer.fit_transform(sentiment_documents)\n",
    "\n",
    "print(f\"\\n✓ Sentiment TF-IDF Matrix: {sentiment_tfidf_matrix.shape}\")\n",
    "print(f\"  Documents: {sentiment_tfidf_matrix.shape[0]:,}\")\n",
    "print(f\"  N-gram Features: {sentiment_tfidf_matrix.shape[1]:,}\")\n",
    "print(f\"  Sparsity: {(1 - sentiment_tfidf_matrix.nnz / (sentiment_tfidf_matrix.shape[0] * sentiment_tfidf_matrix.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef23d8",
   "metadata": {},
   "source": [
    "## 13. Prepare Sentiment Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4569b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sent = sentiment_tfidf_matrix\n",
    "y_sent = np.array(sentiment_labels)\n",
    "\n",
    "# Split data with stratification\n",
    "X_sent_train, X_sent_test, y_sent_train, y_sent_test = train_test_split(\n",
    "    X_sent, y_sent, test_size=0.2, random_state=42, stratify=y_sent\n",
    ")\n",
    "\n",
    "print(f\"Sentiment Training set: {X_sent_train.shape[0]} samples\")\n",
    "print(f\"Sentiment Test set: {X_sent_test.shape[0]} samples\")\n",
    "print(f\"N-gram features: {X_sent_train.shape[1]}\")\n",
    "print(f\"\\nSentiment distribution (train):\")\n",
    "print(pd.Series(y_sent_train).value_counts())\n",
    "print(f\"\\nSentiment distribution (test):\")\n",
    "print(pd.Series(y_sent_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3429af2",
   "metadata": {},
   "source": [
    "## 14. Train Sentiment Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05017f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Naive Bayes for sentiment\n",
    "print(\"Training Sentiment Naive Bayes model with n-grams...\")\n",
    "sent_nb_model = MultinomialNB()\n",
    "sent_nb_model.fit(X_sent_train, y_sent_train)\n",
    "\n",
    "# Make predictions\n",
    "sent_nb_train_pred = sent_nb_model.predict(X_sent_train)\n",
    "sent_nb_test_pred = sent_nb_model.predict(X_sent_test)\n",
    "\n",
    "print(\"✓ Sentiment Naive Bayes training completed\")\n",
    "print(f\"  Classes: {sent_nb_model.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bda2f5",
   "metadata": {},
   "source": [
    "## 15. Evaluate Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate sentiment model\n",
    "sent_nb_train_metrics = evaluate_model(y_sent_train, sent_nb_train_pred, \"Sentiment Naive Bayes (N-gram)\", \"Training\")\n",
    "sent_nb_test_metrics = evaluate_model(y_sent_test, sent_nb_test_pred, \"Sentiment Naive Bayes (N-gram)\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1611ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report (Sentiment - Test Set):\")\n",
    "print(classification_report(y_sent_test, sent_nb_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f283d3a",
   "metadata": {},
   "source": [
    "## 16. Sentiment Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2dc91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot sentiment confusion matrix\n",
    "sent_nb_cm = confusion_matrix(y_sent_test, sent_nb_test_pred)\n",
    "sent_classes = sorted(list(set(y_sent_test)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(sent_nb_cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=sent_classes, yticklabels=sent_classes, cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Naive Bayes with N-grams (Sentiment)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1a710",
   "metadata": {},
   "source": [
    "## 17. Save Sentiment Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sentiment model\n",
    "with open('models/sentiment_naive_bayes_tfidf_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(sent_nb_model, f)\n",
    "\n",
    "# Save sentiment vectorizer\n",
    "with open('models/sentiment_tfidf_vectorizer_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(sentiment_tfidf_vectorizer, f)\n",
    "\n",
    "# Save evaluation report\n",
    "sent_report = {\n",
    "    'model': 'MultinomialNB',\n",
    "    'vectorizer': 'TfidfVectorizer',\n",
    "    'ngram_range': '(1,2)',\n",
    "    'max_features': 10000,\n",
    "    'train_metrics': sent_nb_train_metrics,\n",
    "    'test_metrics': sent_nb_test_metrics,\n",
    "    'classification_report': classification_report(y_sent_test, sent_nb_test_pred, output_dict=True, zero_division=0)\n",
    "}\n",
    "\n",
    "with open('reports/sentiment_naive_bayes_tfidf_ngram_report.json', 'w') as f:\n",
    "    json.dump(sent_report, f, indent=2)\n",
    "\n",
    "print(\"✓ Sentiment model saved to models/sentiment_naive_bayes_tfidf_ngram.pkl\")\n",
    "print(\"✓ Sentiment vectorizer saved to models/sentiment_tfidf_vectorizer_ngram.pkl\")\n",
    "print(\"✓ Sentiment report saved to reports/sentiment_naive_bayes_tfidf_ngram_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd44627",
   "metadata": {},
   "source": [
    "## 18. Final Summary\n",
    "\n",
    "**Model Performance Summary with N-grams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c1f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TF-IDF N-GRAM + NAIVE BAYES CLASSIFICATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nCATEGORY CLASSIFICATION:\")\n",
    "print(f\"  Dataset: {len(documents)} documents\")\n",
    "print(f\"  N-gram Range: (1, 2) - Unigrams + Bigrams\")\n",
    "print(f\"  Feature Count: {X_train.shape[1]:,} n-grams\")\n",
    "print(f\"  Train/Test Split: {X_train.shape[0]}/{X_test.shape[0]}\")\n",
    "print(f\"  Test Accuracy: {nb_test_metrics['accuracy']:.4f} ({nb_test_metrics['accuracy']*100:.2f}%)\")\n",
    "print(f\"  Test F1-Score: {nb_test_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nSENTIMENT CLASSIFICATION:\")\n",
    "print(f\"  Dataset: {len(sentiment_documents)} documents\")\n",
    "print(f\"  N-gram Range: (1, 2) - Unigrams + Bigrams\")\n",
    "print(f\"  Feature Count: {X_sent_train.shape[1]:,} n-grams\")\n",
    "print(f\"  Train/Test Split: {X_sent_train.shape[0]}/{X_sent_test.shape[0]}\")\n",
    "print(f\"  Test Accuracy: {sent_nb_test_metrics['accuracy']:.4f} ({sent_nb_test_metrics['accuracy']*100:.2f}%)\")\n",
    "print(f\"  Test F1-Score: {sent_nb_test_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nKEY FEATURES:\")\n",
    "print(\"  ✓ TF-IDF vectorization with n-grams (1,2)\")\n",
    "print(\"  ✓ Multinomial Naive Bayes classifier\")\n",
    "print(\"  ✓ Captures word sequences and context\")\n",
    "print(\"  ✓ More discriminative features than unigrams\")\n",
    "print(\"  ✓ Document frequency filtering\")\n",
    "print(\"  ✓ Fast training and prediction\")\n",
    "\n",
    "print(\"\\nN-GRAM ADVANTAGES:\")\n",
    "print(\"  ✓ Word pair features (e.g., 'இலங்கை அரசு')\")\n",
    "print(\"  ✓ Better context understanding\")\n",
    "print(\"  ✓ Improved phrase recognition\")\n",
    "print(\"  ✓ Enhanced classification accuracy\")\n",
    "\n",
    "print(\"\\nSAVED ARTIFACTS:\")\n",
    "print(\"  Models:\")\n",
    "print(\"    - models/category_naive_bayes_tfidf_ngram.pkl\")\n",
    "print(\"    - models/sentiment_naive_bayes_tfidf_ngram.pkl\")\n",
    "print(\"  Vectorizers:\")\n",
    "print(\"    - models/category_tfidf_vectorizer_ngram.pkl\")\n",
    "print(\"    - models/sentiment_tfidf_vectorizer_ngram.pkl\")\n",
    "print(\"  Reports:\")\n",
    "print(\"    - reports/category_naive_bayes_tfidf_ngram_report.json\")\n",
    "print(\"    - reports/sentiment_naive_bayes_tfidf_ngram_report.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TF-IDF N-GRAM CLASSIFICATION PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
