{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0add3f6a",
   "metadata": {},
   "source": [
    "# TF-IDF Text Classification with Naive Bayes\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **TF-IDF Vectorization** using scikit-learn\n",
    "2. **Naive Bayes Classification** for Tamil news articles\n",
    "3. **Model Evaluation** with comprehensive metrics\n",
    "\n",
    "**Features:**\n",
    "- Unigram TF-IDF features (max 10,000 features)\n",
    "- Document frequency filtering (min_df=3, max_df=0.8)\n",
    "- Multinomial Naive Bayes classifier\n",
    "- Dual task: Category classification and Sentiment classification\n",
    "\n",
    "**Dataset:** Tamil news articles with categories and processed text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab828d",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fa712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc1dbc",
   "metadata": {},
   "source": [
    "## 2. Load the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data from preprocessing notebook\n",
    "df = pd.read_csv('output/processed_data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data distribution\n",
    "print(\"Category distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nTotal samples: {len(df)}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d60af",
   "metadata": {},
   "source": [
    "## 3. Prepare Text Data for TF-IDF\n",
    "\n",
    "We'll use the `cleaned_title` column which contains preprocessed Tamil text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the text column and target variable\n",
    "documents = df['cleaned_title'].fillna('').tolist()\n",
    "labels = df['category'].tolist()\n",
    "\n",
    "print(f\"Total documents: {len(documents)}\")\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "print(f\"\\nSample document: {documents[0]}\")\n",
    "print(f\"Sample label: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba6102",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Vectorization\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** converts text into numerical features:\n",
    "- **TF**: Measures how frequently a term appears in a document\n",
    "- **IDF**: Measures how important a term is across all documents\n",
    "- **TF-IDF**: Combines both to get weighted features\n",
    "\n",
    "**Parameters:**\n",
    "- `max_features=10000`: Keep only top 10,000 most important words\n",
    "- `min_df=3`: Ignore terms appearing in less than 3 documents\n",
    "- `max_df=0.8`: Ignore terms appearing in more than 80% of documents\n",
    "- `ngram_range=(1,1)`: Use only single words (unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 1),  # Unigrams only\n",
    "    token_pattern=r'\\S+',  # Split on whitespace\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# Fit and transform the documents\n",
    "print(\"Creating TF-IDF matrix...\")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "print(f\"\\n✓ TF-IDF Matrix created: {tfidf_matrix.shape}\")\n",
    "print(f\"  Documents: {tfidf_matrix.shape[0]:,}\")\n",
    "print(f\"  Features: {tfidf_matrix.shape[1]:,}\")\n",
    "print(f\"  Matrix type: {type(tfidf_matrix)}\")\n",
    "print(f\"  Data type: {tfidf_matrix.dtype}\")\n",
    "print(f\"  Sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c53a5",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Machine Learning\n",
    "\n",
    "Split the data into training (80%) and testing (20%) sets with stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53933e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TF-IDF matrix as features\n",
    "X = tfidf_matrix\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split data: 80% train, 20% test with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Feature dimension: {X_train.shape[1]}\")\n",
    "print(f\"\\nTraining set label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set label distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3c5d5",
   "metadata": {},
   "source": [
    "## 6. Train Naive Bayes Model\n",
    "\n",
    "**Naive Bayes** is a probabilistic classifier based on Bayes' theorem:\n",
    "- **Fast training and prediction**\n",
    "- **Works well with text data**\n",
    "- **Assumes independence between features**\n",
    "- **MultinomialNB** is designed for discrete features like word counts/TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d398ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Naive Bayes model\n",
    "print(\"Training Naive Bayes model...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_train_pred = nb_model.predict(X_train)\n",
    "nb_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "print(\"✓ Naive Bayes training completed\")\n",
    "print(f\"  Classes: {nb_model.classes_}\")\n",
    "print(f\"  Number of classes: {len(nb_model.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e461a5c",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Evaluate the model using multiple metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: How many selected items are relevant\n",
    "- **Recall**: How many relevant items are selected\n",
    "- **F1-Score**: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with multiple metrics.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} - {dataset_name} Set\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Evaluate on training and test sets\n",
    "nb_train_metrics = evaluate_model(y_train, nb_train_pred, \"Naive Bayes\", \"Training\")\n",
    "nb_test_metrics = evaluate_model(y_test, nb_test_pred, \"Naive Bayes\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, nb_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa6cc67",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix\n",
    "\n",
    "Visualize the confusion matrix to see which categories are confused with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "nb_cm = confusion_matrix(y_test, nb_test_pred)\n",
    "classes = sorted(list(set(y_test)))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(nb_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes, cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Naive Bayes (Category Classification)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5dfee2",
   "metadata": {},
   "source": [
    "## 9. Save Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae389a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# Save the trained model\n",
    "with open('models/category_naive_bayes_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_model, f)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open('models/category_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# Save evaluation report\n",
    "import json\n",
    "\n",
    "report = {\n",
    "    'model': 'MultinomialNB',\n",
    "    'vectorizer': 'TfidfVectorizer',\n",
    "    'ngram_range': '(1,1)',\n",
    "    'max_features': 10000,\n",
    "    'train_metrics': nb_train_metrics,\n",
    "    'test_metrics': nb_test_metrics,\n",
    "    'classification_report': classification_report(y_test, nb_test_pred, output_dict=True, zero_division=0)\n",
    "}\n",
    "\n",
    "with open('reports/category_naive_bayes_tfidf_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"✓ Model saved to models/category_naive_bayes_tfidf.pkl\")\n",
    "print(\"✓ Vectorizer saved to models/category_tfidf_vectorizer.pkl\")\n",
    "print(\"✓ Evaluation report saved to reports/category_naive_bayes_tfidf_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a57ebe4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SENTIMENT CLASSIFICATION\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd7fc0",
   "metadata": {},
   "source": [
    "## 10. Load Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment data\n",
    "df_sentiment = pd.read_csv('output/processed_sentiment_data.csv')\n",
    "\n",
    "print(f\"Sentiment Dataset shape: {df_sentiment.shape}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df_sentiment['sentiment'].value_counts())\n",
    "\n",
    "sentiment_documents = df_sentiment['tokenized_title'].fillna('').tolist()\n",
    "sentiment_labels = df_sentiment['sentiment'].tolist()\n",
    "\n",
    "print(f\"\\nTotal sentiment documents: {len(sentiment_documents)}\")\n",
    "print(f\"Sample: {sentiment_documents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8256d",
   "metadata": {},
   "source": [
    "## 11. TF-IDF Vectorization for Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb629107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer for sentiment\n",
    "sentiment_tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 1),  # Unigrams only\n",
    "    token_pattern=r'\\S+',\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "# Fit and transform sentiment documents\n",
    "print(\"Creating TF-IDF matrix for sentiment...\")\n",
    "sentiment_tfidf_matrix = sentiment_tfidf_vectorizer.fit_transform(sentiment_documents)\n",
    "\n",
    "print(f\"\\n✓ Sentiment TF-IDF Matrix: {sentiment_tfidf_matrix.shape}\")\n",
    "print(f\"  Documents: {sentiment_tfidf_matrix.shape[0]:,}\")\n",
    "print(f\"  Features: {sentiment_tfidf_matrix.shape[1]:,}\")\n",
    "print(f\"  Sparsity: {(1 - sentiment_tfidf_matrix.nnz / (sentiment_tfidf_matrix.shape[0] * sentiment_tfidf_matrix.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752bfeb",
   "metadata": {},
   "source": [
    "## 12. Prepare Sentiment Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sent = sentiment_tfidf_matrix\n",
    "y_sent = np.array(sentiment_labels)\n",
    "\n",
    "# Split data with stratification\n",
    "X_sent_train, X_sent_test, y_sent_train, y_sent_test = train_test_split(\n",
    "    X_sent, y_sent, test_size=0.2, random_state=42, stratify=y_sent\n",
    ")\n",
    "\n",
    "print(f\"Sentiment Training set: {X_sent_train.shape[0]} samples\")\n",
    "print(f\"Sentiment Test set: {X_sent_test.shape[0]} samples\")\n",
    "print(f\"Features: {X_sent_train.shape[1]}\")\n",
    "print(f\"\\nSentiment distribution (train):\")\n",
    "print(pd.Series(y_sent_train).value_counts())\n",
    "print(f\"\\nSentiment distribution (test):\")\n",
    "print(pd.Series(y_sent_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da3300",
   "metadata": {},
   "source": [
    "## 13. Train Sentiment Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Naive Bayes for sentiment\n",
    "print(\"Training Sentiment Naive Bayes model...\")\n",
    "sent_nb_model = MultinomialNB()\n",
    "sent_nb_model.fit(X_sent_train, y_sent_train)\n",
    "\n",
    "# Make predictions\n",
    "sent_nb_train_pred = sent_nb_model.predict(X_sent_train)\n",
    "sent_nb_test_pred = sent_nb_model.predict(X_sent_test)\n",
    "\n",
    "print(\"✓ Sentiment Naive Bayes training completed\")\n",
    "print(f\"  Classes: {sent_nb_model.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314a6c3",
   "metadata": {},
   "source": [
    "## 14. Evaluate Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate sentiment model\n",
    "sent_nb_train_metrics = evaluate_model(y_sent_train, sent_nb_train_pred, \"Sentiment Naive Bayes\", \"Training\")\n",
    "sent_nb_test_metrics = evaluate_model(y_sent_test, sent_nb_test_pred, \"Sentiment Naive Bayes\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report (Sentiment - Test Set):\")\n",
    "print(classification_report(y_sent_test, sent_nb_test_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154efb5",
   "metadata": {},
   "source": [
    "## 15. Sentiment Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot sentiment confusion matrix\n",
    "sent_nb_cm = confusion_matrix(y_sent_test, sent_nb_test_pred)\n",
    "sent_classes = sorted(list(set(y_sent_test)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(sent_nb_cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=sent_classes, yticklabels=sent_classes, cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Naive Bayes (Sentiment Classification)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2989e6e",
   "metadata": {},
   "source": [
    "## 16. Save Sentiment Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ad0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sentiment model\n",
    "with open('models/sentiment_naive_bayes_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(sent_nb_model, f)\n",
    "\n",
    "# Save sentiment vectorizer\n",
    "with open('models/sentiment_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(sentiment_tfidf_vectorizer, f)\n",
    "\n",
    "# Save evaluation report\n",
    "sent_report = {\n",
    "    'model': 'MultinomialNB',\n",
    "    'vectorizer': 'TfidfVectorizer',\n",
    "    'ngram_range': '(1,1)',\n",
    "    'max_features': 10000,\n",
    "    'train_metrics': sent_nb_train_metrics,\n",
    "    'test_metrics': sent_nb_test_metrics,\n",
    "    'classification_report': classification_report(y_sent_test, sent_nb_test_pred, output_dict=True, zero_division=0)\n",
    "}\n",
    "\n",
    "with open('reports/sentiment_naive_bayes_tfidf_report.json', 'w') as f:\n",
    "    json.dump(sent_report, f, indent=2)\n",
    "\n",
    "print(\"✓ Sentiment model saved to models/sentiment_naive_bayes_tfidf.pkl\")\n",
    "print(\"✓ Sentiment vectorizer saved to models/sentiment_tfidf_vectorizer.pkl\")\n",
    "print(\"✓ Sentiment report saved to reports/sentiment_naive_bayes_tfidf_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1442f7",
   "metadata": {},
   "source": [
    "## 17. Final Summary\n",
    "\n",
    "**Model Performance Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef4e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TF-IDF + NAIVE BAYES CLASSIFICATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nCATEGORY CLASSIFICATION:\")\n",
    "print(f\"  Dataset: {len(documents)} documents\")\n",
    "print(f\"  Feature Count: {X_train.shape[1]:,} unigrams\")\n",
    "print(f\"  Train/Test Split: {X_train.shape[0]}/{X_test.shape[0]}\")\n",
    "print(f\"  Test Accuracy: {nb_test_metrics['accuracy']:.4f} ({nb_test_metrics['accuracy']*100:.2f}%)\")\n",
    "print(f\"  Test F1-Score: {nb_test_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nSENTIMENT CLASSIFICATION:\")\n",
    "print(f\"  Dataset: {len(sentiment_documents)} documents\")\n",
    "print(f\"  Feature Count: {X_sent_train.shape[1]:,} unigrams\")\n",
    "print(f\"  Train/Test Split: {X_sent_train.shape[0]}/{X_sent_test.shape[0]}\")\n",
    "print(f\"  Test Accuracy: {sent_nb_test_metrics['accuracy']:.4f} ({sent_nb_test_metrics['accuracy']*100:.2f}%)\")\n",
    "print(f\"  Test F1-Score: {sent_nb_test_metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nKEY FEATURES:\")\n",
    "print(\"  ✓ TF-IDF vectorization with sklearn\")\n",
    "print(\"  ✓ Multinomial Naive Bayes classifier\")\n",
    "print(\"  ✓ Unigram features (1,1)\")\n",
    "print(\"  ✓ Document frequency filtering\")\n",
    "print(\"  ✓ Fast training and prediction\")\n",
    "\n",
    "print(\"\\nSAVED ARTIFACTS:\")\n",
    "print(\"  Models:\")\n",
    "print(\"    - models/category_naive_bayes_tfidf.pkl\")\n",
    "print(\"    - models/sentiment_naive_bayes_tfidf.pkl\")\n",
    "print(\"  Vectorizers:\")\n",
    "print(\"    - models/category_tfidf_vectorizer.pkl\")\n",
    "print(\"    - models/sentiment_tfidf_vectorizer.pkl\")\n",
    "print(\"  Reports:\")\n",
    "print(\"    - reports/category_naive_bayes_tfidf_report.json\")\n",
    "print(\"    - reports/sentiment_naive_bayes_tfidf_report.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TF-IDF CLASSIFICATION PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
