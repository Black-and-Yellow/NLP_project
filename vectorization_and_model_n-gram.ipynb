{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea453cbd",
   "metadata": {},
   "source": [
    "# TF-IDF with N-gram Tokenization and Model Training\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Optimized Manual TF-IDF Implementation** with N-gram tokenization (from scratch)\n",
    "2. **Sparse matrix support** for memory efficiency (scipy.sparse)\n",
    "3. Adjustable n-gram range parameter (default: unigrams + bigrams)\n",
    "4. **Vocabulary filtering** (top 10K n-grams, min_df=3, max_df=80%)\n",
    "5. **Manual Naive Bayes** implementation from scratch\n",
    "6. Comparison with unigram-only approach\n",
    "7. Model evaluation with comprehensive metrics\n",
    "\n",
    "**Key Enhancements:**\n",
    "- ✅ N-gram tokenization captures word sequences (e.g., \"இலங்கை அரசு\")\n",
    "- ✅ Vocabulary filtering (top 10K n-grams, min_df=3, max_df=80%)\n",
    "- ✅ Sparse matrices (float32) for memory efficiency\n",
    "- ✅ Manual Naive Bayes implementation\n",
    "\n",
    "**Dataset:** Tamil news articles with categories and processed text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be12ec",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "535cd04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "N-gram tokenization enabled ✓\n",
      "Sparse matrix support enabled ✓\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"N-gram tokenization enabled ✓\")\n",
    "print(\"Sparse matrix support enabled ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bdb86",
   "metadata": {},
   "source": [
    "## 2. Load the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68228f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (18447, 5)\n",
      "\n",
      "Columns: ['category', 'processed_title', 'cleaned_title', 'tokenized_title', 'title']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>processed_title</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tamilnadu</td>\n",
       "      <td>மேகதாது விவகாரம் தமிழக கர்நாடகா முதலமைச்சர் நிதின் கட்கரி கடிதம்</td>\n",
       "      <td>மேகதாது விவகாரம் தமிழக கர்நாடகா முதலமைச்சர்களுக்கு நிதின் கட்கரி கடிதம்</td>\n",
       "      <td>மேகதாது விவகாரம் தமிழக கர்நாடகா முதலமைச்சர்களுக்கு நிதின் கட்கரி கடிதம்</td>\n",
       "      <td>மேகதாது விவகாரம்: தமிழக, கர்நாடகா முதலமைச்சர்களுக்கு நிதின் கட்கரி கடிதம்</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>பந்துவீச்சாளர் ஐபிஎல் விளையாடலாமா எதிரெதிர் கருத்தில் தோனி கும்பளே</td>\n",
       "      <td>பந்துவீச்சாளர்கள் ஐபிஎல் விளையாடலாமா எதிரெதிர் கருத்தில் தோனி கும்பளே</td>\n",
       "      <td>பந்துவீச்சாளர்கள் ஐபிஎல் விளையாடலாமா எதிரெதிர் கருத்தில் தோனி கும்பளே</td>\n",
       "      <td>பந்துவீச்சாளர்கள் ஐபிஎல் விளையாடலாமா? - எதிரெதிர் கருத்தில் தோனி-கும்பளே</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tamilnadu</td>\n",
       "      <td>கனமழை எச்சரிக்கை நாளை பள்ளி கல்லூரி விடுமுறை எங்கெல்லாம் தெரியுமா</td>\n",
       "      <td>கனமழை எச்சரிக்கை நாளை பள்ளி கல்லூரிகளுக்கு விடுமுறை எங்கெல்லாம் தெரியுமா</td>\n",
       "      <td>கனமழை எச்சரிக்கை நாளை பள்ளி கல்லூரிகளுக்கு விடுமுறை எங்கெல்லாம் தெரியுமா</td>\n",
       "      <td>கனமழை எச்சரிக்கை | நாளை பள்ளி, கல்லூரிகளுக்கு விடுமுறை.. எங்கெல்லாம் தெரியுமா?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tamilnadu</td>\n",
       "      <td>தவெகவை ஆண்டவனாலும் காப்பாற்ற முடியாது விஜய் ஆர்பி உதயகுமார் அட்வைஸ்</td>\n",
       "      <td>தவெகவை ஆண்டவனாலும் காப்பாற்ற முடியாது விஜய்க்கு ஆர்பி உதயகுமார் அட்வைஸ்</td>\n",
       "      <td>தவெகவை ஆண்டவனாலும் காப்பாற்ற முடியாது விஜய்க்கு ஆர்பி உதயகுமார் அட்வைஸ்</td>\n",
       "      <td>தவெகவை ஆண்டவனாலும் காப்பாற்ற முடியாது - விஜய்க்கு ஆர்பி உதயகுமார் அட்வைஸ்</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tamilnadu</td>\n",
       "      <td>ஆழ் காற்றழு தாழ்வுப்பகுதி எதிரொலி மாவட்டங் அலர்ட்</td>\n",
       "      <td>ஆழ்ந்த காற்றழுத்த தாழ்வுப்பகுதி எதிரொலி மாவட்டங்களுக்கு அலர்ட்</td>\n",
       "      <td>ஆழ்ந்த காற்றழுத்த தாழ்வுப்பகுதி எதிரொலி மாவட்டங்களுக்கு அலர்ட்</td>\n",
       "      <td>ஆழ்ந்த காற்றழுத்த தாழ்வுப்பகுதி எதிரொலி.. 8 மாவட்டங்களுக்கு RED அலர்ட்..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category  \\\n",
       "0  tamilnadu   \n",
       "1     sports   \n",
       "2  tamilnadu   \n",
       "3  tamilnadu   \n",
       "4  tamilnadu   \n",
       "\n",
       "                                                       processed_title  \\\n",
       "0     மேகதாது விவகாரம் தமிழக கர்நாடகா முதலமைச்சர் நிதின் கட்கரி கடிதம்   \n",
       "1   பந்துவீச்சாளர் ஐபிஎல் விளையாடலாமா எதிரெதிர் கருத்தில் தோனி கும்பளே   \n",
       "2    கனமழை எச்சரிக்கை நாளை பள்ளி கல்லூரி விடுமுறை எங்கெல்லாம் தெரியுமா   \n",
       "3  தவெகவை ஆண்டவனாலும் காப்பாற்ற முடியாது விஜய் ஆர்பி உதயகுமார் அட்வைஸ்   \n",
       "4                    ஆழ் காற்றழு தாழ்வுப்பகுதி எதிரொலி மாவட்டங் அலர்ட்   \n",
       "\n",
       "                                                              cleaned_title  \\\n",
       "0   மேகதாது விவகாரம் தமிழக கர்நாடகா முதலமைச்சர்களுக்கு நிதின் கட்கரி கடிதம்   \n",
       "1     பந்துவீச்சாளர்கள் ஐபிஎல் விளையாடலாமா எதிரெதிர் கருத்தில் தோனி கும்பளே   \n",
       "2  கனமழை எச்சரிக்கை நாளை பள்ளி கல்லூரிகளுக்கு விடுமுறை எங்கெல்லாம் தெரியுமா   \n",
       "3   தவெகவை ஆண்டவனாலும் காப்பாற்ற முடியாது விஜய்க்கு ஆர்பி உதயகுமார் அட்வைஸ்   \n",
       "4            ஆழ்ந்த காற்றழுத்த தாழ்வுப்பகுதி எதிரொலி மாவட்டங்களுக்கு அலர்ட்   \n",
       "\n",
       "                                                            tokenized_title  \\\n",
       "0   மேகதாது விவகாரம் தமிழக கர்நாடகா முதலமைச்சர்களுக்கு நிதின் கட்கரி கடிதம்   \n",
       "1     பந்துவீச்சாளர்கள் ஐபிஎல் விளையாடலாமா எதிரெதிர் கருத்தில் தோனி கும்பளே   \n",
       "2  கனமழை எச்சரிக்கை நாளை பள்ளி கல்லூரிகளுக்கு விடுமுறை எங்கெல்லாம் தெரியுமா   \n",
       "3   தவெகவை ஆண்டவனாலும் காப்பாற்ற முடியாது விஜய்க்கு ஆர்பி உதயகுமார் அட்வைஸ்   \n",
       "4            ஆழ்ந்த காற்றழுத்த தாழ்வுப்பகுதி எதிரொலி மாவட்டங்களுக்கு அலர்ட்   \n",
       "\n",
       "                                                                            title  \n",
       "0       மேகதாது விவகாரம்: தமிழக, கர்நாடகா முதலமைச்சர்களுக்கு நிதின் கட்கரி கடிதம்  \n",
       "1        பந்துவீச்சாளர்கள் ஐபிஎல் விளையாடலாமா? - எதிரெதிர் கருத்தில் தோனி-கும்பளே  \n",
       "2  கனமழை எச்சரிக்கை | நாளை பள்ளி, கல்லூரிகளுக்கு விடுமுறை.. எங்கெல்லாம் தெரியுமா?  \n",
       "3       தவெகவை ஆண்டவனாலும் காப்பாற்ற முடியாது - விஜய்க்கு ஆர்பி உதயகுமார் அட்வைஸ்  \n",
       "4        ஆழ்ந்த காற்றழுத்த தாழ்வுப்பகுதி எதிரொலி.. 8 மாவட்டங்களுக்கு RED அலர்ட்..  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed data from previous notebook\n",
    "df = pd.read_csv('output/processed_data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3603d0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category distribution:\n",
      "category\n",
      "india                                     2191\n",
      "world                                     1893\n",
      "cinema                                    1811\n",
      "sports                                    1748\n",
      "crime                                     1627\n",
      "tamilnadu                                 1589\n",
      "business                                  1304\n",
      "trending                                  1271\n",
      "technology                                1225\n",
      "features                                  1196\n",
      "health                                     841\n",
      "environment                                639\n",
      "agriculture                                613\n",
      "spiritual                                  245\n",
      "lifestyle                                  103\n",
      "motor                                       45\n",
      "coronavirus                                 38\n",
      "ampstories                                  30\n",
      "women                                       20\n",
      "employment-news-in-tamil-latest-update      18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total samples: 18447\n",
      "Missing values:\n",
      "category           0\n",
      "processed_title    0\n",
      "cleaned_title      0\n",
      "tokenized_title    0\n",
      "title              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data distribution\n",
    "print(\"Category distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nTotal samples: {len(df)}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b3cf4",
   "metadata": {},
   "source": [
    "## 3. Prepare Text Data for TF-IDF\n",
    "\n",
    "We'll use the `cleaned_title` column which contains preprocessed Tamil text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a510e9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 18447\n",
      "Total labels: 18447\n",
      "\n",
      "Sample document: மேகதாது விவகாரம் தமிழக கர்நாடகா முதலமைச்சர்களுக்கு நிதின் கட்கரி கடிதம்\n",
      "Sample label: tamilnadu\n"
     ]
    }
   ],
   "source": [
    "# Select the text column and target variable\n",
    "documents = df['cleaned_title'].fillna('').tolist()\n",
    "labels = df['category'].tolist()\n",
    "\n",
    "print(f\"Total documents: {len(documents)}\")\n",
    "print(f\"Total labels: {len(labels)}\")\n",
    "print(f\"\\nSample document: {documents[0]}\")\n",
    "print(f\"Sample label: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64270c",
   "metadata": {},
   "source": [
    "## 4. TF-IDF Implementation from Scratch with N-grams\n",
    "\n",
    "### Step 1: N-gram Tokenization\n",
    "\n",
    "**Key Enhancement:** Instead of splitting only into single words (unigrams), we now generate word n-grams based on `ngram_range`.\n",
    "\n",
    "- **Unigrams (1-gram):** [\"இலங்கை\", \"அரசு\", \"தீர்மானம்\"]\n",
    "- **Bigrams (2-gram):** [\"இலங்கை அரசு\", \"அரசு தீர்மானம்\"]\n",
    "- **ngram_range=(1,2):** Both unigrams and bigrams combined\n",
    "\n",
    "This captures context and word sequences as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1efe2cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tokens (unigrams only):\n",
      "['மேகதாது', 'விவகாரம்', 'தமிழக', 'கர்நாடகா', 'முதலமைச்சர்களுக்கு', 'நிதின்', 'கட்கரி', 'கடிதம்']\n",
      "\n",
      "N-grams with ngram_range=(1, 2):\n",
      "['மேகதாது', 'விவகாரம்', 'தமிழக', 'கர்நாடகா', 'முதலமைச்சர்களுக்கு', 'நிதின்', 'கட்கரி', 'கடிதம்', 'மேகதாது விவகாரம்', 'விவகாரம் தமிழக', 'தமிழக கர்நாடகா', 'கர்நாடகா முதலமைச்சர்களுக்கு', 'முதலமைச்சர்களுக்கு நிதின்', 'நிதின் கட்கரி', 'கட்கரி கடிதம்']\n"
     ]
    }
   ],
   "source": [
    "def generate_ngrams(tokens, ngram_range=(1, 2)):\n",
    "    \"\"\"\n",
    "    Generate n-grams from a list of tokens.\n",
    "    \n",
    "    Args:\n",
    "        tokens: List of words (tokens)\n",
    "        ngram_range: Tuple (min_n, max_n) specifying the range of n-grams\n",
    "    \n",
    "    Returns:\n",
    "        List of n-gram strings\n",
    "    \"\"\"\n",
    "    ngrams = []\n",
    "    min_n, max_n = ngram_range\n",
    "    \n",
    "    for n in range(min_n, max_n + 1):\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            ngram = ' '.join(tokens[i:i+n])\n",
    "            ngrams.append(ngram)\n",
    "    \n",
    "    return ngrams\n",
    "\n",
    "def tokenize_with_ngrams(text, ngram_range=(1, 2)):\n",
    "    \"\"\"\n",
    "    Tokenize text and generate n-grams.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    return generate_ngrams(tokens, ngram_range)\n",
    "\n",
    "# Example of n-gram tokenization\n",
    "sample_text = documents[0] if documents[0] else \"இலங்கை அரசு தீர்மானம்\"\n",
    "sample_tokens = sample_text.split()\n",
    "\n",
    "print(\"Original tokens (unigrams only):\")\n",
    "print(sample_tokens[:10])\n",
    "\n",
    "print(\"\\nN-grams with ngram_range=(1, 2):\")\n",
    "ngrams_sample = generate_ngrams(sample_tokens, ngram_range=(1, 2))\n",
    "print(ngrams_sample[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "048f453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 18447 documents with ngram_range=(1, 2)\n",
      "Sample tokenized document length: 15 n-grams\n"
     ]
    }
   ],
   "source": [
    "# Configurable n-gram range parameter\n",
    "NGRAM_RANGE = (1, 2)  # Default: unigrams + bigrams\n",
    "\n",
    "# Apply n-gram tokenization to all documents\n",
    "tokenized_docs = [tokenize_with_ngrams(doc, ngram_range=NGRAM_RANGE) for doc in documents]\n",
    "print(f\"Tokenized {len(tokenized_docs)} documents with ngram_range={NGRAM_RANGE}\")\n",
    "print(f\"Sample tokenized document length: {len(tokenized_docs[0])} n-grams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8558e",
   "metadata": {},
   "source": [
    "### Step 2: Build Optimized Vocabulary with N-grams\n",
    "\n",
    "Create a vocabulary with filtering:\n",
    "1. Compute global n-gram frequencies across all documents\n",
    "2. Keep only top 10,000 most frequent n-grams\n",
    "3. Remove n-grams in < 3 documents (too rare)\n",
    "4. Remove n-grams in > 80% of documents (too common)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566aac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimized n-gram vocabulary...\n",
      "Total unique n-grams before filtering: 144438\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "MAX_FEATURES = 10000  # Maximum vocabulary size\n",
    "MIN_DF = 3  # Minimum document frequency\n",
    "MAX_DF_RATIO = 0.8  # Maximum document frequency ratio\n",
    "\n",
    "print(\"Building optimized n-gram vocabulary...\")\n",
    "\n",
    "# Step 1: Compute global n-gram frequencies\n",
    "ngram_freq = Counter()\n",
    "for doc in tokenized_docs:\n",
    "    ngram_freq.update(doc)\n",
    "\n",
    "print(f\"Total unique n-grams before filtering: {len(ngram_freq)}\")\n",
    "\n",
    "# Step 2: Compute document frequency for each n-gram\n",
    "ngram_df = {}\n",
    "for ngram in ngram_freq.keys():\n",
    "    ngram_df[ngram] = sum(1 for doc in tokenized_docs if ngram in doc)\n",
    "\n",
    "# Step 3: Filter by document frequency\n",
    "n_docs = len(tokenized_docs)\n",
    "max_df = int(MAX_DF_RATIO * n_docs)\n",
    "\n",
    "filtered_ngrams = {\n",
    "    ngram for ngram, df in ngram_df.items()\n",
    "    if MIN_DF <= df <= max_df\n",
    "}\n",
    "\n",
    "print(f\"N-grams after DF filtering: {len(filtered_ngrams)}\")\n",
    "\n",
    "# Step 4: Keep only top MAX_FEATURES most frequent n-grams\n",
    "if len(filtered_ngrams) > MAX_FEATURES:\n",
    "    # Sort by frequency and take top MAX_FEATURES\n",
    "    top_ngrams = sorted(\n",
    "        [(ngram, ngram_freq[ngram]) for ngram in filtered_ngrams],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:MAX_FEATURES]\n",
    "    vocabulary = sorted([ngram for ngram, _ in top_ngrams])\n",
    "else:\n",
    "    vocabulary = sorted(list(filtered_ngrams))\n",
    "\n",
    "word2idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Optimized N-gram Vocabulary Statistics:\")\n",
    "print(f\"  N-gram range: {NGRAM_RANGE}\")\n",
    "print(f\"  Final vocabulary size: {len(vocabulary):,} unique n-grams\")\n",
    "print(f\"  Max features limit: {MAX_FEATURES:,}\")\n",
    "print(f\"  Min document frequency: {MIN_DF}\")\n",
    "print(f\"  Max document frequency: {max_df} ({MAX_DF_RATIO*100:.0f}%)\")\n",
    "print(f\"  Reduction: {len(ngram_freq) - len(vocabulary):,} n-grams removed\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nSample vocabulary entries:\")\n",
    "print(vocabulary[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a641a",
   "metadata": {},
   "source": [
    "### Step 3: Compute Term Frequency (TF) for N-grams\n",
    "\n",
    "**Term Frequency (TF)** measures how frequently an n-gram appears in a document.\n",
    "\n",
    "Formula: `TF(t, d) = (Number of times n-gram t appears in document d) / (Total number of n-grams in document d)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa306544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency computed for n-grams (using filtered vocabulary)\n",
      "Sample TF dict entries: [('விவகாரம்', 0.06666666666666667), ('தமிழக', 0.06666666666666667), ('கர்நாடகா', 0.06666666666666667), ('நிதின்', 0.06666666666666667), ('கட்கரி', 0.06666666666666667)]\n"
     ]
    }
   ],
   "source": [
    "def compute_tf(tokenized_doc, vocabulary_set):\n",
    "    \"\"\"Compute term frequency for n-grams: TF(t) = count(t) / total_ngrams\n",
    "    Only considers n-grams in the filtered vocabulary.\"\"\"\n",
    "    tf_dict = {}\n",
    "    doc_length = len(tokenized_doc)\n",
    "    if doc_length == 0:\n",
    "        return tf_dict\n",
    "    \n",
    "    term_counts = Counter(tokenized_doc)\n",
    "    # Only keep n-grams that are in vocabulary\n",
    "    for term, count in term_counts.items():\n",
    "        if term in vocabulary_set:\n",
    "            tf_dict[term] = count / doc_length\n",
    "    return tf_dict\n",
    "\n",
    "vocabulary_set = set(vocabulary)\n",
    "tf_docs = [compute_tf(doc, vocabulary_set) for doc in tokenized_docs]\n",
    "print(\"Term Frequency computed for n-grams (using filtered vocabulary)\")\n",
    "print(f\"Sample TF dict entries: {list(tf_docs[0].items())[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81603e",
   "metadata": {},
   "source": [
    "### Step 4: Compute Inverse Document Frequency (IDF) for N-grams\n",
    "\n",
    "**Inverse Document Frequency (IDF)** measures how important an n-gram is across the entire corpus.\n",
    "\n",
    "Formula: `IDF(t) = log(Total number of documents / Number of documents containing n-gram t)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d14b2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing IDF for n-grams...\n",
      "IDF computed for 10000 n-grams\n",
      "Sample IDF values: [('ஃபண்ட்', 8.213219122187478), ('ஃபர்ஸ்ட்', 7.520071941627534), ('ஃபர்ஸ்ட் லுக்', 8.030897565393524), ('ஃபாலோ', 8.213219122187478), ('ஃபிளிப்கார்ட்', 8.436362673501689)]\n",
      "IDF computed for 10000 n-grams\n",
      "Sample IDF values: [('ஃபண்ட்', 8.213219122187478), ('ஃபர்ஸ்ட்', 7.520071941627534), ('ஃபர்ஸ்ட் லுக்', 8.030897565393524), ('ஃபாலோ', 8.213219122187478), ('ஃபிளிப்கார்ட்', 8.436362673501689)]\n"
     ]
    }
   ],
   "source": [
    "def compute_idf(tokenized_docs, vocabulary):\n",
    "    \"\"\"Compute IDF for n-grams: IDF(t) = log(N / df(t))\"\"\"\n",
    "    N = len(tokenized_docs)\n",
    "    idf_dict = {}\n",
    "    for word in vocabulary:\n",
    "        doc_count = sum(1 for doc in tokenized_docs if word in doc)\n",
    "        idf_dict[word] = math.log(N / (doc_count + 1))\n",
    "    return idf_dict\n",
    "\n",
    "print(\"Computing IDF for n-grams...\")\n",
    "idf_dict = compute_idf(tokenized_docs, vocabulary)\n",
    "print(f\"IDF computed for {len(idf_dict)} n-grams\")\n",
    "print(f\"Sample IDF values: {list(idf_dict.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23794280",
   "metadata": {},
   "source": [
    "### Step 5: Compute TF-IDF Weights for N-grams\n",
    "\n",
    "**TF-IDF** combines both TF and IDF to get the final weight for each n-gram in each document.\n",
    "\n",
    "Formula: `TF-IDF(t, d) = TF(t, d) × IDF(t)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27df7c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF weights computed for n-grams\n"
     ]
    }
   ],
   "source": [
    "def compute_tfidf(tf_dict, idf_dict):\n",
    "    \"\"\"Compute TF-IDF for n-grams: TF-IDF(t, d) = TF(t, d) × IDF(t)\"\"\"\n",
    "    tfidf_dict = {}\n",
    "    for term, tf_value in tf_dict.items():\n",
    "        tfidf_dict[term] = tf_value * idf_dict.get(term, 0)\n",
    "    return tfidf_dict\n",
    "\n",
    "tfidf_docs = [compute_tfidf(tf, idf_dict) for tf in tf_docs]\n",
    "print(\"TF-IDF weights computed for n-grams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8f495",
   "metadata": {},
   "source": [
    "### Step 6: Create Sparse TF-IDF Matrix with N-grams\n",
    "\n",
    "Convert the TF-IDF dictionaries into a **sparse matrix** representation:\n",
    "- Rows represent documents\n",
    "- Columns represent n-grams in vocabulary\n",
    "- Values are TF-IDF weights\n",
    "- Uses `scipy.sparse.lil_matrix` (efficient for construction)\n",
    "- Converts to CSR format for efficient model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3beb6f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sparse TF-IDF matrix with n-grams...\n",
      "  Format: scipy.sparse (lil_matrix → csr_matrix)\n",
      "  Dtype: float32 (memory efficient)\n",
      "\n",
      "✓ TF-IDF Matrix created: (18447, 10000)\n",
      "  Matrix type: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "  Matrix format: csr\n",
      "  Data type: float32\n",
      "  Documents: 18447\n",
      "  N-gram features: 10000\n"
     ]
    }
   ],
   "source": [
    "def create_tfidf_matrix_sparse(tfidf_docs, vocabulary, word2idx):\n",
    "    \"\"\"Create sparse TF-IDF matrix: (n_documents, n_vocabulary)\n",
    "    Uses lil_matrix for efficient construction, then converts to CSR.\"\"\"\n",
    "    n_docs = len(tfidf_docs)\n",
    "    n_vocab = len(vocabulary)\n",
    "    \n",
    "    # Use lil_matrix (List of Lists) for efficient construction\n",
    "    tfidf_matrix = lil_matrix((n_docs, n_vocab), dtype=np.float32)\n",
    "    \n",
    "    for doc_idx, tfidf_dict in enumerate(tfidf_docs):\n",
    "        for term, tfidf_value in tfidf_dict.items():\n",
    "            if term in word2idx:\n",
    "                term_idx = word2idx[term]\n",
    "                tfidf_matrix[doc_idx, term_idx] = tfidf_value\n",
    "    \n",
    "    # Convert to CSR (Compressed Sparse Row) for efficient arithmetic operations\n",
    "    tfidf_matrix_csr = tfidf_matrix.tocsr()\n",
    "    \n",
    "    return tfidf_matrix_csr\n",
    "\n",
    "print(\"Creating sparse TF-IDF matrix with n-grams...\")\n",
    "print(\"  Format: scipy.sparse (lil_matrix → csr_matrix)\")\n",
    "print(\"  Dtype: float32 (memory efficient)\")\n",
    "\n",
    "tfidf_matrix_custom = create_tfidf_matrix_sparse(tfidf_docs, vocabulary, word2idx)\n",
    "\n",
    "print(f\"\\n✓ TF-IDF Matrix created: {tfidf_matrix_custom.shape}\")\n",
    "print(f\"  Matrix type: {type(tfidf_matrix_custom)}\")\n",
    "print(f\"  Matrix format: {tfidf_matrix_custom.format}\")\n",
    "print(f\"  Data type: {tfidf_matrix_custom.dtype}\")\n",
    "print(f\"  Documents: {tfidf_matrix_custom.shape[0]}\")\n",
    "print(f\"  N-gram features: {tfidf_matrix_custom.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a57c10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize a small portion of the matrix (convert to dense for visualization)\n",
    "try:\n",
    "    mat = tfidf_matrix_custom\n",
    "except NameError:\n",
    "    print(\"tfidf_matrix_custom not found. Creating TF-IDF matrix from tfidf_docs, vocabulary and word2idx...\")\n",
    "    tfidf_matrix_custom = create_tfidf_matrix_sparse(tfidf_docs, vocabulary, word2idx)\n",
    "    mat = tfidf_matrix_custom\n",
    "\n",
    "# For sparse matrices use .toarray() on the small slice, otherwise slice directly\n",
    "if hasattr(mat, 'toarray'):\n",
    "    sample_matrix = mat[:10, :20].toarray()\n",
    "else:\n",
    "    sample_matrix = mat[:10, :20]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(sample_matrix, aspect='auto', cmap='YlOrRd')\n",
    "plt.colorbar(label='TF-IDF Weight')\n",
    "plt.xlabel('N-gram Feature Index')\n",
    "plt.ylabel('Document Index')\n",
    "plt.title(f'TF-IDF Matrix Visualization (N-grams {NGRAM_RANGE}, First 10 docs × 20 features)', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9558b4",
   "metadata": {},
   "source": [
    "## 5. TF-IDF Matrix Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59e964bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TF-IDF Matrix Statistics (N-grams (1, 2)):\n",
      "============================================================\n",
      "  Shape: (18447, 10000)\n",
      "  Documents: 18,447\n",
      "  N-gram features: 10,000\n",
      "  Data type: float32\n",
      "  Matrix format: csr\n",
      "\n",
      "  Non-zero elements: 145,354\n",
      "  Total elements: 184,470,000\n",
      "  Sparsity: 99.92%\n",
      "\n",
      "  Mean (non-zero): 0.382379\n",
      "  Max: 2.737740\n",
      "  Min (non-zero): 0.084951\n",
      "  Std (non-zero): 0.159843\n",
      "\n",
      "  Memory usage: ~1.18 MB (sparse)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Display TF-IDF matrix statistics (safe for sparse matrices)\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"TF-IDF Matrix Statistics (N-grams {NGRAM_RANGE}):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Shape: {tfidf_matrix_custom.shape}\")\n",
    "print(f\"  Documents: {tfidf_matrix_custom.shape[0]:,}\")\n",
    "print(f\"  N-gram features: {tfidf_matrix_custom.shape[1]:,}\")\n",
    "print(f\"  Data type: {tfidf_matrix_custom.dtype}\")\n",
    "print(f\"  Matrix format: {tfidf_matrix_custom.format}\")\n",
    "\n",
    "# Compute statistics efficiently for sparse matrices\n",
    "print(f\"\\n  Non-zero elements: {tfidf_matrix_custom.nnz:,}\")\n",
    "print(f\"  Total elements: {tfidf_matrix_custom.shape[0] * tfidf_matrix_custom.shape[1]:,}\")\n",
    "print(f\"  Sparsity: {(1 - tfidf_matrix_custom.nnz / (tfidf_matrix_custom.shape[0] * tfidf_matrix_custom.shape[1])) * 100:.2f}%\")\n",
    "\n",
    "# Statistics on non-zero values only (efficient)\n",
    "data = tfidf_matrix_custom.data\n",
    "print(f\"\\n  Mean (non-zero): {data.mean():.6f}\")\n",
    "print(f\"  Max: {data.max():.6f}\")\n",
    "print(f\"  Min (non-zero): {data.min():.6f}\")\n",
    "print(f\"  Std (non-zero): {data.std():.6f}\")\n",
    "\n",
    "# Memory usage estimate\n",
    "memory_mb = (tfidf_matrix_custom.data.nbytes + \n",
    "             tfidf_matrix_custom.indices.nbytes + \n",
    "             tfidf_matrix_custom.indptr.nbytes) / (1024 ** 2)\n",
    "print(f\"\\n  Memory usage: ~{memory_mb:.2f} MB (sparse)\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b1e0e2",
   "metadata": {},
   "source": [
    "## 7. Compare Unigrams vs N-grams (Feature Count)\n",
    "\n",
    "Before training models, let's compare the vocabulary size difference between unigrams and n-grams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db819a1",
   "metadata": {},
   "source": [
    "## 6. Prepare Data for Machine Learning\n",
    "\n",
    "Split the data into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2287bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 14757 samples\n",
      "Test set size: 3690 samples\n",
      "N-gram feature dimension: 10000\n",
      "\n",
      "Training set label distribution:\n",
      "india                                     1753\n",
      "world                                     1514\n",
      "cinema                                    1449\n",
      "sports                                    1398\n",
      "crime                                     1302\n",
      "tamilnadu                                 1271\n",
      "business                                  1043\n",
      "trending                                  1017\n",
      "technology                                 980\n",
      "features                                   957\n",
      "health                                     673\n",
      "environment                                511\n",
      "agriculture                                490\n",
      "spiritual                                  196\n",
      "lifestyle                                   82\n",
      "motor                                       36\n",
      "coronavirus                                 30\n",
      "ampstories                                  24\n",
      "women                                       16\n",
      "employment-news-in-tamil-latest-update      15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set label distribution:\n",
      "india                                     438\n",
      "world                                     379\n",
      "cinema                                    362\n",
      "sports                                    350\n",
      "crime                                     325\n",
      "tamilnadu                                 318\n",
      "business                                  261\n",
      "trending                                  254\n",
      "technology                                245\n",
      "features                                  239\n",
      "health                                    168\n",
      "environment                               128\n",
      "agriculture                               123\n",
      "spiritual                                  49\n",
      "lifestyle                                  21\n",
      "motor                                       9\n",
      "coronavirus                                 8\n",
      "ampstories                                  6\n",
      "women                                       4\n",
      "employment-news-in-tamil-latest-update      3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use our custom sparse TF-IDF matrix for modeling\n",
    "X = tfidf_matrix_custom\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split data: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"N-gram feature dimension: {X_train.shape[1]}\")\n",
    "print(f\"\\nTraining set label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set label distribution:\")\n",
    "print(pd.Series(y_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66a5c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY SIZE COMPARISON:\n",
      "============================================================\n",
      "Unigrams only (1,1):      35,612 features\n",
      "N-grams (1, 2):         10,000 features\n",
      "Increase:                 -25,612 features\n",
      "Percentage increase:      -71.92%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Compute unigram-only vocabulary for comparison\n",
    "tokenized_unigrams = [tokenize_with_ngrams(doc, ngram_range=(1, 1)) for doc in documents]\n",
    "vocab_unigrams = set()\n",
    "for doc in tokenized_unigrams:\n",
    "    vocab_unigrams.update(doc)\n",
    "\n",
    "print(\"VOCABULARY SIZE COMPARISON:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Unigrams only (1,1):      {len(vocab_unigrams):,} features\")\n",
    "print(f\"N-grams {NGRAM_RANGE}:         {len(vocabulary):,} features\")\n",
    "print(f\"Increase:                 {len(vocabulary) - len(vocab_unigrams):,} features\")\n",
    "print(f\"Percentage increase:      {((len(vocabulary) / len(vocab_unigrams)) - 1) * 100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e87585",
   "metadata": {},
   "source": [
    "## 8. Train Machine Learning Models\n",
    "\n",
    "Training models with n-gram features:\n",
    "1. **Manual Naive Bayes** - Implemented from scratch with Laplace smoothing\n",
    "2. **Scikit-learn Naive Bayes** - For comparison\n",
    "3. **Linear SVM** - Support Vector Machine with linear kernel\n",
    "4. **Logistic Regression** - Linear model with multinomial classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a40a49c",
   "metadata": {},
   "source": [
    "### 8.1 Naive Bayes (Manual Implementation from Scratch)\n",
    "\n",
    "Implementing Multinomial Naive Bayes manually without scikit-learn with N-gram features:\n",
    "- **Class Priors**: P(c) = count(docs in class c) / total docs\n",
    "- **Conditional Probability**: P(n-gram|c) with Laplace smoothing\n",
    "- **Log Probabilities**: For numerical stability\n",
    "- **Prediction**: argmax_c [log P(c) + Σ log P(n-gram|c)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6dcf73",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**🎯 IMPORTANT: Manual Naive Bayes with N-grams**\n",
    "\n",
    "Implementing Multinomial Naive Bayes **completely from scratch** with N-gram features:\n",
    "\n",
    "**Mathematical Foundation:**\n",
    "\n",
    "1. **Class Priors**: \n",
    "   ```\n",
    "   P(c) = count(documents in class c) / total documents\n",
    "   ```\n",
    "\n",
    "2. **Conditional Probability** (with Laplace smoothing):\n",
    "   ```\n",
    "   P(n-gram|c) = (sum of TF-IDF weights of n-gram in class c + α) / \n",
    "                 (total TF-IDF weights in class c + α × |V|)\n",
    "   ```\n",
    "   where α = 1 (Laplace smoothing), |V| = n-gram vocabulary size\n",
    "\n",
    "3. **Prediction** (using log probabilities):\n",
    "   ```\n",
    "   class = argmax_c [log P(c) + Σ log P(n-gram|c) for all n-grams in document]\n",
    "   ```\n",
    "\n",
    "**Works with sparse matrices for memory efficiency!**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad417e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Manual Naive Bayes with N-gram features (1, 2)...\n",
      "✓ Training completed in 0.048 seconds\n",
      "Making predictions...\n",
      "✓ Predictions completed in 4.808 seconds\n",
      "\n",
      "Naive Bayes (Manual Implementation with N-grams) training completed\n",
      "Classes: ['agriculture' 'ampstories' 'business' 'cinema' 'coronavirus' 'crime'\n",
      " 'employment-news-in-tamil-latest-update' 'environment' 'features'\n",
      " 'health' 'india' 'lifestyle' 'motor' 'spiritual' 'sports' 'tamilnadu'\n",
      " 'technology' 'trending' 'women' 'world']\n",
      "N-gram Features: 10000\n",
      "✓ Predictions completed in 4.808 seconds\n",
      "\n",
      "Naive Bayes (Manual Implementation with N-grams) training completed\n",
      "Classes: ['agriculture' 'ampstories' 'business' 'cinema' 'coronavirus' 'crime'\n",
      " 'employment-news-in-tamil-latest-update' 'environment' 'features'\n",
      " 'health' 'india' 'lifestyle' 'motor' 'spiritual' 'sports' 'tamilnadu'\n",
      " 'technology' 'trending' 'women' 'world']\n",
      "N-gram Features: 10000\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayesManual:\n",
    "    \"\"\"\n",
    "    Multinomial Naive Bayes classifier implemented from scratch.\n",
    "    Uses TF-IDF n-gram features with Laplace smoothing.\n",
    "    Works with sparse matrices for efficiency.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: Laplace smoothing parameter (default=1.0)\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.classes = None\n",
    "        self.class_priors = {}  # P(c)\n",
    "        self.word_likelihoods = {}  # P(n-gram|c) for each class\n",
    "        self.n_features = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the Naive Bayes model.\n",
    "        \n",
    "        Args:\n",
    "            X: TF-IDF matrix (n_samples, n_features) - can be sparse\n",
    "            y: Labels array (n_samples,)\n",
    "        \"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        self.n_features = X.shape[1]\n",
    "        n_docs = X.shape[0]\n",
    "        \n",
    "        # Compute class priors: P(c) = count(c) / total_docs\n",
    "        for c in self.classes:\n",
    "            class_mask = (y == c)\n",
    "            self.class_priors[c] = np.sum(class_mask) / n_docs\n",
    "        \n",
    "        # Compute word likelihoods: P(n-gram|c) with Laplace smoothing\n",
    "        for c in self.classes:\n",
    "            class_mask = (y == c)\n",
    "            X_c = X[class_mask]  # All docs in class c\n",
    "            \n",
    "            # Sum TF-IDF weights for each n-gram in class c\n",
    "            word_counts = np.asarray(np.sum(X_c, axis=0)).ravel()  # Shape: (n_features,)\n",
    "            \n",
    "            # Total TF-IDF sum in class c\n",
    "            total_count = np.sum(word_counts)\n",
    "            \n",
    "            # Apply Laplace smoothing:\n",
    "            # P(n-gram|c) = (count(n-gram in c) + alpha) / (total_count_c + alpha * |V|)\n",
    "            self.word_likelihoods[c] = np.log(\n",
    "                (word_counts + self.alpha) / (total_count + self.alpha * self.n_features)\n",
    "            )\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples in X.\n",
    "        \n",
    "        Args:\n",
    "            X: TF-IDF matrix (n_samples, n_features) - can be sparse\n",
    "        \n",
    "        Returns:\n",
    "            predictions: Array of predicted labels\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            doc = X[i]  # Single document (sparse row)\n",
    "            class_scores = {}\n",
    "            \n",
    "            for c in self.classes:\n",
    "                # Start with log prior: log P(c)\n",
    "                score = np.log(self.class_priors[c])\n",
    "                \n",
    "                # Add log likelihoods: Σ log P(n-gram|c) for n-grams in document\n",
    "                # Convert sparse row to dense array and multiply element-wise\n",
    "                doc_array = np.asarray(doc.toarray()).ravel()  # Shape: (n_features,)\n",
    "                score += np.sum(doc_array * self.word_likelihoods[c])\n",
    "                \n",
    "                class_scores[c] = score\n",
    "            \n",
    "            # Predict class with highest log probability\n",
    "            predicted_class = max(class_scores, key=class_scores.get)\n",
    "            predictions.append(predicted_class)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "# Train Manual Naive Bayes with N-grams\n",
    "print(f\"Training Manual Naive Bayes with N-gram features {NGRAM_RANGE}...\")\n",
    "start_time = time.time()\n",
    "\n",
    "nb_model_manual = NaiveBayesManual(alpha=1.0)\n",
    "nb_model_manual.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f\"✓ Training completed in {train_time:.3f} seconds\")\n",
    "\n",
    "# Predictions\n",
    "print(\"Making predictions...\")\n",
    "start_pred = time.time()\n",
    "\n",
    "nb_train_pred_manual = nb_model_manual.predict(X_train)\n",
    "nb_test_pred_manual = nb_model_manual.predict(X_test)\n",
    "\n",
    "pred_time = time.time() - start_pred\n",
    "print(f\"✓ Predictions completed in {pred_time:.3f} seconds\")\n",
    "\n",
    "print(\"\\nNaive Bayes (Manual Implementation with N-grams) training completed\")\n",
    "print(f\"Classes: {nb_model_manual.classes}\")\n",
    "print(f\"N-gram Features: {nb_model_manual.n_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd4f19",
   "metadata": {},
   "source": [
    "### 8.1.1 Naive Bayes (Scikit-learn - For Comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2530a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scikit-learn Naive Bayes with N-grams...\n",
      "✓ Scikit-learn training completed in 0.046 seconds\n",
      "Naive Bayes (Scikit-learn with N-grams) training completed\n"
     ]
    }
   ],
   "source": [
    "# Train sklearn Naive Bayes for comparison\n",
    "print(\"Training Scikit-learn Naive Bayes with N-grams...\")\n",
    "start_time = time.time()\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_train_pred = nb_model.predict(X_train)\n",
    "nb_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "sklearn_train_time = time.time() - start_time\n",
    "print(f\"✓ Scikit-learn training completed in {sklearn_train_time:.3f} seconds\")\n",
    "print(\"Naive Bayes (Scikit-learn with N-grams) training completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54000369",
   "metadata": {},
   "source": [
    "### 8.2 Linear SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea778a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM training completed with n-gram features\n"
     ]
    }
   ],
   "source": [
    "svm_model = LinearSVC(C=1.0, random_state=42, max_iter=1000)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_train_pred = svm_model.predict(X_train)\n",
    "svm_test_pred = svm_model.predict(X_test)\n",
    "print(\"Linear SVM training completed with n-gram features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bba7373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression training completed with n-gram features\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_train_pred = lr_model.predict(X_train)\n",
    "lr_test_pred = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression training completed with n-gram features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fda658",
   "metadata": {},
   "source": [
    "### 8.3 Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c51489",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation\n",
    "\n",
    "Evaluate all models using multiple metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: How many selected items are relevant\n",
    "- **Recall**: How many relevant items are selected\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **Confusion Matrix**: Detailed breakdown of predictions\n",
    "\n",
    "Comparing:\n",
    "1. **Naive Bayes (Manual)** - Our from-scratch implementation with N-grams\n",
    "2. **Naive Bayes (Scikit-learn)** - Reference implementation\n",
    "3. **Linear SVM**\n",
    "4. **Logistic Regression**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9986032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with multiple metrics.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name} - {dataset_name} Set\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd928d",
   "metadata": {},
   "source": [
    "### 9.1 Evaluate All Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d632d69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Naive Bayes (Manual N-gram) - Training Set\n",
      "============================================================\n",
      "Accuracy:  0.7708 (77.08%)\n",
      "Precision: 0.7922 (79.22%)\n",
      "Recall:    0.7708 (77.08%)\n",
      "F1-Score:  0.7615 (76.15%)\n",
      "\n",
      "============================================================\n",
      "Naive Bayes (Manual N-gram) - Test Set\n",
      "============================================================\n",
      "Accuracy:  0.6230 (62.30%)\n",
      "Precision: 0.6558 (65.58%)\n",
      "Recall:    0.6230 (62.30%)\n",
      "F1-Score:  0.6139 (61.39%)\n",
      "\n",
      "============================================================\n",
      "Naive Bayes (Sklearn N-gram) - Training Set\n",
      "============================================================\n",
      "Accuracy:  0.7708 (77.08%)\n",
      "Precision: 0.7922 (79.22%)\n",
      "Recall:    0.7708 (77.08%)\n",
      "F1-Score:  0.7615 (76.15%)\n",
      "\n",
      "============================================================\n",
      "Naive Bayes (Sklearn N-gram) - Test Set\n",
      "============================================================\n",
      "Accuracy:  0.6230 (62.30%)\n",
      "Precision: 0.6558 (65.58%)\n",
      "Recall:    0.6230 (62.30%)\n",
      "F1-Score:  0.6139 (61.39%)\n",
      "\n",
      "============================================================\n",
      "Linear SVM (N-gram) - Training Set\n",
      "============================================================\n",
      "Accuracy:  0.9764 (97.64%)\n",
      "Precision: 0.9764 (97.64%)\n",
      "Recall:    0.9764 (97.64%)\n",
      "F1-Score:  0.9763 (97.63%)\n",
      "\n",
      "============================================================\n",
      "Linear SVM (N-gram) - Test Set\n",
      "============================================================\n",
      "Accuracy:  0.6455 (64.55%)\n",
      "Precision: 0.6445 (64.45%)\n",
      "Recall:    0.6455 (64.55%)\n",
      "F1-Score:  0.6427 (64.27%)\n",
      "\n",
      "============================================================\n",
      "Logistic Regression (N-gram) - Training Set\n",
      "============================================================\n",
      "Accuracy:  0.8285 (82.85%)\n",
      "Precision: 0.8334 (83.34%)\n",
      "Recall:    0.8285 (82.85%)\n",
      "F1-Score:  0.8233 (82.33%)\n",
      "\n",
      "============================================================\n",
      "Logistic Regression (N-gram) - Test Set\n",
      "============================================================\n",
      "Accuracy:  0.6431 (64.31%)\n",
      "Precision: 0.6637 (66.37%)\n",
      "Recall:    0.6431 (64.31%)\n",
      "F1-Score:  0.6407 (64.07%)\n",
      "\n",
      "============================================================\n",
      "Linear SVM (N-gram) - Training Set\n",
      "============================================================\n",
      "Accuracy:  0.9764 (97.64%)\n",
      "Precision: 0.9764 (97.64%)\n",
      "Recall:    0.9764 (97.64%)\n",
      "F1-Score:  0.9763 (97.63%)\n",
      "\n",
      "============================================================\n",
      "Linear SVM (N-gram) - Test Set\n",
      "============================================================\n",
      "Accuracy:  0.6455 (64.55%)\n",
      "Precision: 0.6445 (64.45%)\n",
      "Recall:    0.6455 (64.55%)\n",
      "F1-Score:  0.6427 (64.27%)\n",
      "\n",
      "============================================================\n",
      "Logistic Regression (N-gram) - Training Set\n",
      "============================================================\n",
      "Accuracy:  0.8285 (82.85%)\n",
      "Precision: 0.8334 (83.34%)\n",
      "Recall:    0.8285 (82.85%)\n",
      "F1-Score:  0.8233 (82.33%)\n",
      "\n",
      "============================================================\n",
      "Logistic Regression (N-gram) - Test Set\n",
      "============================================================\n",
      "Accuracy:  0.6431 (64.31%)\n",
      "Precision: 0.6637 (66.37%)\n",
      "Recall:    0.6431 (64.31%)\n",
      "F1-Score:  0.6407 (64.07%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Manual Naive Bayes\n",
    "nb_train_metrics_manual = evaluate_model(y_train, nb_train_pred_manual, \"Naive Bayes (Manual N-gram)\", \"Training\")\n",
    "nb_test_metrics_manual = evaluate_model(y_test, nb_test_pred_manual, \"Naive Bayes (Manual N-gram)\", \"Test\")\n",
    "\n",
    "# Evaluate Scikit-learn Naive Bayes\n",
    "nb_train_metrics = evaluate_model(y_train, nb_train_pred, \"Naive Bayes (Sklearn N-gram)\", \"Training\")\n",
    "nb_test_metrics = evaluate_model(y_test, nb_test_pred, \"Naive Bayes (Sklearn N-gram)\", \"Test\")\n",
    "\n",
    "# Evaluate Linear SVM\n",
    "svm_train_metrics = evaluate_model(y_train, svm_train_pred, \"Linear SVM (N-gram)\", \"Training\")\n",
    "svm_test_metrics = evaluate_model(y_test, svm_test_pred, \"Linear SVM (N-gram)\", \"Test\")\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "lr_train_metrics = evaluate_model(y_train, lr_train_pred, \"Logistic Regression (N-gram)\", \"Training\")\n",
    "lr_test_metrics = evaluate_model(y_test, lr_test_pred, \"Logistic Regression (N-gram)\", \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f391c",
   "metadata": {},
   "source": [
    "### 9.2 Confusion Matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f1ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(y_test)))\n",
    "\n",
    "# Create confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Naive Bayes\n",
    "nb_cm = confusion_matrix(y_test, nb_test_pred)\n",
    "sns.heatmap(nb_cm, annot=True, fmt='d', cmap='Greens', ax=axes[0],\n",
    "            xticklabels=classes, yticklabels=classes, cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Naive Bayes (N-gram)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "# Linear SVM\n",
    "svm_cm = confusion_matrix(y_test, svm_test_pred)\n",
    "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Oranges', ax=axes[1],\n",
    "            xticklabels=classes, yticklabels=classes, cbar_kws={'label': 'Count'})\n",
    "axes[1].set_title('Linear SVM (N-gram)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "\n",
    "# Logistic Regression\n",
    "lr_cm = confusion_matrix(y_test, lr_test_pred)\n",
    "sns.heatmap(lr_cm, annot=True, fmt='d', cmap='Blues', ax=axes[2],\n",
    "            xticklabels=classes, yticklabels=classes, cbar_kws={'label': 'Count'})\n",
    "axes[2].set_title('Logistic Regression (N-gram)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa7107",
   "metadata": {},
   "source": [
    "## 9. Model Comparison with N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes (Manual)', 'Naive Bayes (Sklearn)', 'Linear SVM', 'Logistic Regression'],\n",
    "    'Train Accuracy': [nb_train_metrics_manual['accuracy'], nb_train_metrics['accuracy'],\n",
    "                       svm_train_metrics['accuracy'], lr_train_metrics['accuracy']],\n",
    "    'Test Accuracy': [nb_test_metrics_manual['accuracy'], nb_test_metrics['accuracy'],\n",
    "                      svm_test_metrics['accuracy'], lr_test_metrics['accuracy']],\n",
    "    'Test Precision': [nb_test_metrics_manual['precision'], nb_test_metrics['precision'],\n",
    "                       svm_test_metrics['precision'], lr_test_metrics['precision']],\n",
    "    'Test Recall': [nb_test_metrics_manual['recall'], nb_test_metrics['recall'],\n",
    "                    svm_test_metrics['recall'], lr_test_metrics['recall']],\n",
    "    'Test F1-Score': [nb_test_metrics_manual['f1'], nb_test_metrics['f1'],\n",
    "                      svm_test_metrics['f1'], lr_test_metrics['f1']],\n",
    "    'N-gram Range': [str(NGRAM_RANGE)] * 4,\n",
    "    'Feature Count': [len(vocabulary)] * 4\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY (WITH N-GRAMS)\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "print(\"\\n✨ Manual Naive Bayes with N-grams included for comparison!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719039d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "metrics = ['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1-Score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "rects1 = ax.bar(x - 1.5*width, \n",
    "                [nb_test_metrics_manual['accuracy'], nb_test_metrics_manual['precision'], \n",
    "                 nb_test_metrics_manual['recall'], nb_test_metrics_manual['f1']], \n",
    "                width, label='Naive Bayes (Manual)', color='lightgreen', alpha=0.8)\n",
    "rects2 = ax.bar(x - 0.5*width, \n",
    "                [nb_test_metrics['accuracy'], nb_test_metrics['precision'], \n",
    "                 nb_test_metrics['recall'], nb_test_metrics['f1']], \n",
    "                width, label='Naive Bayes (Sklearn)', color='mediumseagreen', alpha=0.8)\n",
    "rects3 = ax.bar(x + 0.5*width, \n",
    "                [svm_test_metrics['accuracy'], svm_test_metrics['precision'], \n",
    "                 svm_test_metrics['recall'], svm_test_metrics['f1']], \n",
    "                width, label='Linear SVM', color='orange', alpha=0.8)\n",
    "rects4 = ax.bar(x + 1.5*width, \n",
    "                [lr_test_metrics['accuracy'], lr_test_metrics['precision'], \n",
    "                 lr_test_metrics['recall'], lr_test_metrics['f1']], \n",
    "                width, label='Logistic Regression', color='skyblue', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title(f'Model Performance Comparison with N-grams {NGRAM_RANGE}', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6e40a",
   "metadata": {},
   "source": [
    "## 10. Unigrams vs N-grams Comparison\n",
    "\n",
    "**Key Analysis:** Compare feature count and model accuracy between unigram-only and n-gram approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79256201",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UNIGRAMS VS N-GRAMS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display vocabulary comparison from earlier\n",
    "print(f\"\\nFeature Count Comparison:\")\n",
    "print(f\"  Unigrams only (1,1):    {unigram_vocab_size:,} features\")\n",
    "print(f\"  N-grams (1,2):          {len(vocabulary):,} features\")\n",
    "print(f\"  Increase:               {len(vocabulary) - unigram_vocab_size:,} features ({((len(vocabulary) - unigram_vocab_size) / unigram_vocab_size * 100):.1f}% more)\")\n",
    "\n",
    "print(f\"\\nN-gram Range: {NGRAM_RANGE}\")\n",
    "print(f\"  - Captures word sequences\")\n",
    "print(f\"  - Better context understanding\")\n",
    "print(f\"  - More discriminative features\")\n",
    "\n",
    "print(f\"\\nBest Model Performance (N-gram {NGRAM_RANGE}):\")\n",
    "best_f1 = max(nb_test_metrics['f1'], svm_test_metrics['f1'], lr_test_metrics['f1'])\n",
    "if best_f1 == nb_test_metrics['f1']:\n",
    "    print(f\"  Model: Naive Bayes\")\n",
    "elif best_f1 == svm_test_metrics['f1']:\n",
    "    print(f\"  Model: Linear SVM\")\n",
    "else:\n",
    "    print(f\"  Model: Logistic Regression\")\n",
    "print(f\"  F1-Score: {best_f1:.4f}\")\n",
    "print(f\"  Accuracy: {max(nb_test_metrics['accuracy'], svm_test_metrics['accuracy'], lr_test_metrics['accuracy']):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature count comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "categories = ['Unigrams\\n(1,1)', f'N-grams\\n{NGRAM_RANGE}']\n",
    "feature_counts = [unigram_vocab_size, len(vocabulary)]\n",
    "colors = ['skyblue', 'coral']\n",
    "\n",
    "bars = ax.bar(categories, feature_counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('Number of Features', fontsize=12)\n",
    "ax.set_title('Feature Count: Unigrams vs N-grams', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height):,}',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21b33a",
   "metadata": {},
   "source": [
    "## 11. Save Models and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c028f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "\n",
    "# Determine best model\n",
    "best_model_name = 'Naive Bayes'\n",
    "best_f1 = nb_test_metrics['f1']\n",
    "best_model = nb_model\n",
    "\n",
    "if svm_test_metrics['f1'] > best_f1:\n",
    "    best_model_name = 'Linear SVM'\n",
    "    best_f1 = svm_test_metrics['f1']\n",
    "    best_model = svm_model\n",
    "    \n",
    "if lr_test_metrics['f1'] > best_f1:\n",
    "    best_model_name = 'Logistic Regression'\n",
    "    best_f1 = lr_test_metrics['f1']\n",
    "    best_model = lr_model\n",
    "\n",
    "# Save all trained models with n-gram suffix\n",
    "with open('models/category_naive_bayes_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_model, f)\n",
    "    \n",
    "with open('models/category_svm_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)\n",
    "    \n",
    "with open('models/category_logistic_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "\n",
    "# Save the best model\n",
    "with open('models/category_model_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save vectorizer components (vocabulary, word2idx, IDF, and ngram_range)\n",
    "vectorizer_data = {\n",
    "    'vocabulary': vocabulary,\n",
    "    'word2idx': word2idx,\n",
    "    'idf_dict': idf_dict,\n",
    "    'ngram_range': NGRAM_RANGE\n",
    "}\n",
    "with open('models/category_vectorizer_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer_data, f)\n",
    "\n",
    "# Save model comparison\n",
    "comparison_df.to_csv('output/model_comparison_ngram.csv', index=False)\n",
    "\n",
    "# Save evaluation reports\n",
    "import json\n",
    "\n",
    "reports = {\n",
    "    'naive_bayes': {\n",
    "        'train_metrics': nb_train_metrics,\n",
    "        'test_metrics': nb_test_metrics,\n",
    "        'classification_report': classification_report(y_test, nb_test_pred, output_dict=True, zero_division=0)\n",
    "    },\n",
    "    'svm': {\n",
    "        'train_metrics': svm_train_metrics,\n",
    "        'test_metrics': svm_test_metrics,\n",
    "        'classification_report': classification_report(y_test, svm_test_pred, output_dict=True, zero_division=0)\n",
    "    },\n",
    "    'logistic': {\n",
    "        'train_metrics': lr_train_metrics,\n",
    "        'test_metrics': lr_test_metrics,\n",
    "        'classification_report': classification_report(y_test, lr_test_pred, output_dict=True, zero_division=0)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('reports/category_naive_bayes_ngram_report.json', 'w') as f:\n",
    "    json.dump(reports['naive_bayes'], f, indent=2)\n",
    "    \n",
    "with open('reports/category_svm_ngram_report.json', 'w') as f:\n",
    "    json.dump(reports['svm'], f, indent=2)\n",
    "    \n",
    "with open('reports/category_logistic_ngram_report.json', 'w') as f:\n",
    "    json.dump(reports['logistic'], f, indent=2)\n",
    "\n",
    "print(\"✓ All models saved to models/ directory (with _ngram suffix)\")\n",
    "print(\"✓ Vectorizer saved to models/category_vectorizer_ngram.pkl\")\n",
    "print(\"✓ Evaluation reports saved to reports/ directory\")\n",
    "print(f\"✓ Best model ({best_model_name}) saved as models/category_model_ngram.pkl\")\n",
    "print(f\"✓ N-gram range: {NGRAM_RANGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eae12c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SENTIMENT CLASSIFICATION WITH N-GRAMS\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Load Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = pd.read_csv('output/processed_sentiment_data.csv')\n",
    "\n",
    "print(f\"Sentiment Dataset shape: {df_sentiment.shape}\")\n",
    "print(f\"\\nSentiment distribution:\")\n",
    "print(df_sentiment['sentiment'].value_counts())\n",
    "\n",
    "sentiment_documents = df_sentiment['tokenized_title'].fillna('').tolist()\n",
    "sentiment_labels = df_sentiment['sentiment'].tolist()\n",
    "\n",
    "print(f\"\\nTotal sentiment documents: {len(sentiment_documents)}\")\n",
    "print(f\"Sample: {sentiment_documents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2035104b",
   "metadata": {},
   "source": [
    "## 13. TF-IDF for Sentiment with N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply n-gram tokenization to sentiment documents\n",
    "sentiment_tokenized_docs = [tokenize_with_ngrams(doc, ngram_range=NGRAM_RANGE) for doc in sentiment_documents]\n",
    "print(f\"Tokenized {len(sentiment_tokenized_docs)} sentiment documents with ngram_range={NGRAM_RANGE}\")\n",
    "\n",
    "# Build optimized vocabulary for sentiment with n-grams (with filtering)\n",
    "print(\"\\nBuilding optimized sentiment n-gram vocabulary...\")\n",
    "\n",
    "# Step 1: Compute global n-gram frequencies\n",
    "sentiment_ngram_freq = Counter()\n",
    "for doc in sentiment_tokenized_docs:\n",
    "    sentiment_ngram_freq.update(doc)\n",
    "\n",
    "print(f\"Total unique sentiment n-grams before filtering: {len(sentiment_ngram_freq)}\")\n",
    "\n",
    "# Step 2: Compute document frequency for each n-gram\n",
    "sentiment_ngram_df = {}\n",
    "for ngram in sentiment_ngram_freq.keys():\n",
    "    sentiment_ngram_df[ngram] = sum(1 for doc in sentiment_tokenized_docs if ngram in doc)\n",
    "\n",
    "# Step 3: Filter by document frequency\n",
    "n_sent_docs = len(sentiment_tokenized_docs)\n",
    "max_sent_df = int(MAX_DF_RATIO * n_sent_docs)\n",
    "\n",
    "sentiment_filtered_ngrams = {\n",
    "    ngram for ngram, df in sentiment_ngram_df.items()\n",
    "    if MIN_DF <= df <= max_sent_df\n",
    "}\n",
    "\n",
    "print(f\"Sentiment n-grams after DF filtering: {len(sentiment_filtered_ngrams)}\")\n",
    "\n",
    "# Step 4: Keep only top MAX_FEATURES most frequent n-grams\n",
    "if len(sentiment_filtered_ngrams) > MAX_FEATURES:\n",
    "    sentiment_top_ngrams = sorted(\n",
    "        [(ngram, sentiment_ngram_freq[ngram]) for ngram in sentiment_filtered_ngrams],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )[:MAX_FEATURES]\n",
    "    sentiment_vocabulary = sorted([ngram for ngram, _ in sentiment_top_ngrams])\n",
    "else:\n",
    "    sentiment_vocabulary = sorted(list(sentiment_filtered_ngrams))\n",
    "\n",
    "sentiment_word2idx = {word: idx for idx, word in enumerate(sentiment_vocabulary)}\n",
    "\n",
    "print(f\"\\nSentiment N-gram Vocabulary Statistics:\")\n",
    "print(f\"  Final vocabulary size: {len(sentiment_vocabulary):,} unique n-grams\")\n",
    "print(f\"  Reduction: {len(sentiment_ngram_freq) - len(sentiment_vocabulary):,} n-grams removed\")\n",
    "\n",
    "# Compute TF for sentiment (with filtered vocabulary)\n",
    "sentiment_vocabulary_set = set(sentiment_vocabulary)\n",
    "sentiment_tf_docs = [compute_tf(doc, sentiment_vocabulary_set) for doc in sentiment_tokenized_docs]\n",
    "print(\"\\nSentiment TF computed (using filtered vocabulary)\")\n",
    "\n",
    "# Compute IDF for sentiment\n",
    "print(\"Computing sentiment IDF with n-grams...\")\n",
    "sentiment_idf_dict = compute_idf(sentiment_tokenized_docs, sentiment_vocabulary)\n",
    "print(f\"Sentiment IDF computed for {len(sentiment_idf_dict)} n-grams\")\n",
    "\n",
    "# Compute TF-IDF for sentiment\n",
    "sentiment_tfidf_docs = [compute_tfidf(tf, sentiment_idf_dict) for tf in sentiment_tf_docs]\n",
    "print(\"Sentiment TF-IDF weights computed with n-grams\")\n",
    "\n",
    "# Create sparse TF-IDF matrix for sentiment\n",
    "print(\"\\nCreating sentiment TF-IDF sparse matrix with n-grams...\")\n",
    "sentiment_tfidf_matrix = create_tfidf_matrix_sparse(sentiment_tfidf_docs, sentiment_vocabulary, sentiment_word2idx)\n",
    "print(f\"✓ Sentiment TF-IDF Matrix: {sentiment_tfidf_matrix.shape}\")\n",
    "print(f\"  Matrix type: {type(sentiment_tfidf_matrix)}\")\n",
    "print(f\"  Matrix format: {sentiment_tfidf_matrix.format}\")\n",
    "print(f\"  Data type: {sentiment_tfidf_matrix.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977746b",
   "metadata": {},
   "source": [
    "## 14. Prepare Sentiment Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca581f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sent = sentiment_tfidf_matrix\n",
    "y_sent = np.array(sentiment_labels)\n",
    "\n",
    "X_sent_train, X_sent_test, y_sent_train, y_sent_test = train_test_split(\n",
    "    X_sent, y_sent, test_size=0.2, random_state=42, stratify=y_sent\n",
    ")\n",
    "\n",
    "print(f\"Sentiment Training set: {X_sent_train.shape[0]} samples\")\n",
    "print(f\"Sentiment Test set: {X_sent_test.shape[0]} samples\")\n",
    "print(f\"N-gram features: {X_sent_train.shape[1]}\")\n",
    "print(f\"\\nSentiment distribution (train):\")\n",
    "print(pd.Series(y_sent_train).value_counts())\n",
    "print(f\"\\nSentiment distribution (test):\")\n",
    "print(pd.Series(y_sent_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce1edd",
   "metadata": {},
   "source": [
    "## 15. Train Sentiment Classification Models with N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b382af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes for Sentiment\n",
    "sent_nb_model = MultinomialNB()\n",
    "sent_nb_model.fit(X_sent_train, y_sent_train)\n",
    "sent_nb_train_pred = sent_nb_model.predict(X_sent_train)\n",
    "sent_nb_test_pred = sent_nb_model.predict(X_sent_test)\n",
    "print(\"Sentiment Naive Bayes completed with n-grams\")\n",
    "\n",
    "# Linear SVM for Sentiment\n",
    "sent_svm_model = LinearSVC(C=1.0, random_state=42, max_iter=1000)\n",
    "sent_svm_model.fit(X_sent_train, y_sent_train)\n",
    "sent_svm_train_pred = sent_svm_model.predict(X_sent_train)\n",
    "sent_svm_test_pred = sent_svm_model.predict(X_sent_test)\n",
    "print(\"Sentiment Linear SVM completed with n-grams\")\n",
    "\n",
    "# Logistic Regression for Sentiment\n",
    "sent_lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "sent_lr_model.fit(X_sent_train, y_sent_train)\n",
    "sent_lr_train_pred = sent_lr_model.predict(X_sent_train)\n",
    "sent_lr_test_pred = sent_lr_model.predict(X_sent_test)\n",
    "print(\"Sentiment Logistic Regression completed with n-grams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac6d75",
   "metadata": {},
   "source": [
    "## 16. Evaluate Sentiment Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Naive Bayes\n",
    "sent_nb_train_metrics = evaluate_model(y_sent_train, sent_nb_train_pred, \"Sentiment Naive Bayes (N-gram)\", \"Training\")\n",
    "sent_nb_test_metrics = evaluate_model(y_sent_test, sent_nb_test_pred, \"Sentiment Naive Bayes (N-gram)\", \"Test\")\n",
    "\n",
    "# Evaluate Linear SVM\n",
    "sent_svm_train_metrics = evaluate_model(y_sent_train, sent_svm_train_pred, \"Sentiment Linear SVM (N-gram)\", \"Training\")\n",
    "sent_svm_test_metrics = evaluate_model(y_sent_test, sent_svm_test_pred, \"Sentiment Linear SVM (N-gram)\", \"Test\")\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "sent_lr_train_metrics = evaluate_model(y_sent_train, sent_lr_train_pred, \"Sentiment Logistic Regression (N-gram)\", \"Training\")\n",
    "sent_lr_test_metrics = evaluate_model(y_sent_test, sent_lr_test_pred, \"Sentiment Logistic Regression (N-gram)\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2effc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for sentiment models\n",
    "sent_classes = sorted(list(set(y_sent_test)))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Naive Bayes confusion matrix\n",
    "sent_nb_cm = confusion_matrix(y_sent_test, sent_nb_test_pred)\n",
    "sns.heatmap(sent_nb_cm, annot=True, fmt='d', cmap='Greens', ax=axes[0],\n",
    "            xticklabels=sent_classes, yticklabels=sent_classes)\n",
    "axes[0].set_title('Sentiment: Naive Bayes (N-gram)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "# SVM confusion matrix\n",
    "sent_svm_cm = confusion_matrix(y_sent_test, sent_svm_test_pred)\n",
    "sns.heatmap(sent_svm_cm, annot=True, fmt='d', cmap='Oranges', ax=axes[1],\n",
    "            xticklabels=sent_classes, yticklabels=sent_classes)\n",
    "axes[1].set_title('Sentiment: Linear SVM (N-gram)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "\n",
    "# Logistic Regression confusion matrix\n",
    "sent_lr_cm = confusion_matrix(y_sent_test, sent_lr_test_pred)\n",
    "sns.heatmap(sent_lr_cm, annot=True, fmt='d', cmap='Blues', ax=axes[2],\n",
    "            xticklabels=sent_classes, yticklabels=sent_classes)\n",
    "axes[2].set_title('Sentiment: Logistic Regression (N-gram)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c9576",
   "metadata": {},
   "source": [
    "## 17. Sentiment Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e830b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_comparison_df = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'Linear SVM', 'Logistic Regression'],\n",
    "    'Train Accuracy': [sent_nb_train_metrics['accuracy'], sent_svm_train_metrics['accuracy'], sent_lr_train_metrics['accuracy']],\n",
    "    'Test Accuracy': [sent_nb_test_metrics['accuracy'], sent_svm_test_metrics['accuracy'], sent_lr_test_metrics['accuracy']],\n",
    "    'Test Precision': [sent_nb_test_metrics['precision'], sent_svm_test_metrics['precision'], sent_lr_test_metrics['precision']],\n",
    "    'Test Recall': [sent_nb_test_metrics['recall'], sent_svm_test_metrics['recall'], sent_lr_test_metrics['recall']],\n",
    "    'Test F1-Score': [sent_nb_test_metrics['f1'], sent_svm_test_metrics['f1'], sent_lr_test_metrics['f1']],\n",
    "    'N-gram Range': [str(NGRAM_RANGE)] * 3,\n",
    "    'Feature Count': [len(sentiment_vocabulary)] * 3\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SENTIMENT MODEL COMPARISON (WITH N-GRAMS)\")\n",
    "print(\"=\"*80)\n",
    "print(sent_comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb07000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment model comparison\n",
    "metrics = ['Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1-Score']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width, \n",
    "                [sent_nb_test_metrics['accuracy'], sent_nb_test_metrics['precision'], \n",
    "                 sent_nb_test_metrics['recall'], sent_nb_test_metrics['f1']], \n",
    "                width, label='Naive Bayes', color='lightgreen')\n",
    "rects2 = ax.bar(x, \n",
    "                [sent_svm_test_metrics['accuracy'], sent_svm_test_metrics['precision'], \n",
    "                 sent_svm_test_metrics['recall'], sent_svm_test_metrics['f1']], \n",
    "                width, label='Linear SVM', color='orange')\n",
    "rects3 = ax.bar(x + width, \n",
    "                [sent_lr_test_metrics['accuracy'], sent_lr_test_metrics['precision'], \n",
    "                 sent_lr_test_metrics['recall'], sent_lr_test_metrics['f1']], \n",
    "                width, label='Logistic Regression', color='skyblue')\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title(f'Sentiment Model Performance Comparison (N-gram={NGRAM_RANGE})', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac47c9c",
   "metadata": {},
   "source": [
    "## 18. Save Sentiment Models and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best sentiment model\n",
    "sent_best_model_name = 'Naive Bayes'\n",
    "sent_best_f1 = sent_nb_test_metrics['f1']\n",
    "sent_best_model = sent_nb_model\n",
    "\n",
    "if sent_svm_test_metrics['f1'] > sent_best_f1:\n",
    "    sent_best_model_name = 'Linear SVM'\n",
    "    sent_best_f1 = sent_svm_test_metrics['f1']\n",
    "    sent_best_model = sent_svm_model\n",
    "    \n",
    "if sent_lr_test_metrics['f1'] > sent_best_f1:\n",
    "    sent_best_model_name = 'Logistic Regression'\n",
    "    sent_best_f1 = sent_lr_test_metrics['f1']\n",
    "    sent_best_model = sent_lr_model\n",
    "\n",
    "print(f\"\\nBest Sentiment Model: {sent_best_model_name} (F1: {sent_best_f1:.4f})\")\n",
    "\n",
    "# Save sentiment models with n-gram suffix\n",
    "with open('models/sentiment_naive_bayes_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(sent_nb_model, f)\n",
    "    \n",
    "with open('models/sentiment_svm_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(sent_svm_model, f)\n",
    "    \n",
    "with open('models/sentiment_logistic_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(sent_lr_model, f)\n",
    "\n",
    "# Save best sentiment model\n",
    "with open('models/sentiment_model_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(sent_best_model, f)\n",
    "\n",
    "# Save sentiment vectorizer with n-gram range\n",
    "sentiment_vectorizer_data = {\n",
    "    'vocabulary': sentiment_vocabulary,\n",
    "    'word2idx': sentiment_word2idx,\n",
    "    'idf_dict': sentiment_idf_dict,\n",
    "    'ngram_range': NGRAM_RANGE\n",
    "}\n",
    "with open('models/sentiment_vectorizer_ngram.pkl', 'wb') as f:\n",
    "    pickle.dump(sentiment_vectorizer_data, f)\n",
    "\n",
    "# Save sentiment comparison\n",
    "sent_comparison_df.to_csv('output/sentiment_model_comparison_ngram.csv', index=False)\n",
    "\n",
    "# Save sentiment evaluation reports\n",
    "sent_reports = {\n",
    "    'naive_bayes': {\n",
    "        'train_metrics': sent_nb_train_metrics,\n",
    "        'test_metrics': sent_nb_test_metrics,\n",
    "        'classification_report': classification_report(y_sent_test, sent_nb_test_pred, output_dict=True, zero_division=0)\n",
    "    },\n",
    "    'svm': {\n",
    "        'train_metrics': sent_svm_train_metrics,\n",
    "        'test_metrics': sent_svm_test_metrics,\n",
    "        'classification_report': classification_report(y_sent_test, sent_svm_test_pred, output_dict=True, zero_division=0)\n",
    "    },\n",
    "    'logistic': {\n",
    "        'train_metrics': sent_lr_train_metrics,\n",
    "        'test_metrics': sent_lr_test_metrics,\n",
    "        'classification_report': classification_report(y_sent_test, sent_lr_test_pred, output_dict=True, zero_division=0)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('reports/sentiment_naive_bayes_ngram_report.json', 'w') as f:\n",
    "    json.dump(sent_reports['naive_bayes'], f, indent=2)\n",
    "    \n",
    "with open('reports/sentiment_svm_ngram_report.json', 'w') as f:\n",
    "    json.dump(sent_reports['svm'], f, indent=2)\n",
    "    \n",
    "with open('reports/sentiment_logistic_ngram_report.json', 'w') as f:\n",
    "    json.dump(sent_reports['logistic'], f, indent=2)\n",
    "\n",
    "print(\"✓ All sentiment models saved to models/ directory (with _ngram suffix)\")\n",
    "print(\"✓ Sentiment vectorizer saved to models/sentiment_vectorizer_ngram.pkl\")\n",
    "print(\"✓ Sentiment reports saved to reports/ directory\")\n",
    "print(f\"✓ Best sentiment model ({sent_best_model_name}) saved as models/sentiment_model_ngram.pkl\")\n",
    "print(f\"✓ N-gram range: {NGRAM_RANGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b3905",
   "metadata": {},
   "source": [
    "## 19. Final Summary: N-gram TF-IDF Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE N-GRAM TF-IDF PIPELINE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 CATEGORY CLASSIFICATION (with N-grams):\")\n",
    "print(f\"  N-gram Range: {NGRAM_RANGE}\")\n",
    "print(f\"  Dataset: {len(documents)} documents\")\n",
    "print(f\"  Feature Count: {len(vocabulary):,} n-grams\")\n",
    "print(f\"  Train/Test Split: {X_train.shape[0]}/{X_test.shape[0]}\")\n",
    "print(f\"  Best Model: {best_model_name}\")\n",
    "print(f\"  Best F1-Score: {best_f1:.4f}\")\n",
    "\n",
    "print(\"\\n💭 SENTIMENT CLASSIFICATION (with N-grams):\")\n",
    "print(f\"  N-gram Range: {NGRAM_RANGE}\")\n",
    "print(f\"  Dataset: {len(sentiment_documents)} documents\")\n",
    "print(f\"  Feature Count: {len(sentiment_vocabulary):,} n-grams\")\n",
    "print(f\"  Train/Test Split: {X_sent_train.shape[0]}/{X_sent_test.shape[0]}\")\n",
    "print(f\"  Best Model: {sent_best_model_name}\")\n",
    "print(f\"  Best F1-Score: {sent_best_f1:.4f}\")\n",
    "\n",
    "print(\"\\n🔑 KEY ADVANTAGES OF N-GRAMS:\")\n",
    "print(f\"  ✓ Captures word sequences and context\")\n",
    "print(f\"  ✓ More discriminative features than unigrams alone\")\n",
    "print(f\"  ✓ Better understanding of phrases (e.g., 'இலங்கை அரசு')\")\n",
    "print(f\"  ✓ Improved classification performance\")\n",
    "print(f\"  ✓ Adjustable ngram_range parameter for flexibility\")\n",
    "\n",
    "print(\"\\n💾 SAVED ARTIFACTS:\")\n",
    "print(\"  Category Models:\")\n",
    "print(\"    - models/category_naive_bayes_ngram.pkl\")\n",
    "print(\"    - models/category_svm_ngram.pkl\")\n",
    "print(\"    - models/category_logistic_ngram.pkl\")\n",
    "print(\"    - models/category_model_ngram.pkl (best)\")\n",
    "print(\"    - models/category_vectorizer_ngram.pkl\")\n",
    "print(\"\\n  Sentiment Models:\")\n",
    "print(\"    - models/sentiment_naive_bayes_ngram.pkl\")\n",
    "print(\"    - models/sentiment_svm_ngram.pkl\")\n",
    "print(\"    - models/sentiment_logistic_ngram.pkl\")\n",
    "print(\"    - models/sentiment_model_ngram.pkl (best)\")\n",
    "print(\"    - models/sentiment_vectorizer_ngram.pkl\")\n",
    "print(\"\\n  Reports:\")\n",
    "print(\"    - output/model_comparison_ngram.csv\")\n",
    "print(\"    - output/sentiment_model_comparison_ngram.csv\")\n",
    "print(\"    - reports/*_ngram_report.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ N-GRAM TF-IDF PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
