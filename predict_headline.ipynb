{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4843f5e7",
   "metadata": {},
   "source": [
    "# Tamil News Headline Prediction System\n",
    "\n",
    "## Comprehensive Multi-Model Prediction System\n",
    "\n",
    "This notebook loads **ALL trained models** and predicts:\n",
    "1. **Category Classification** - Using all 3 models (Naive Bayes, SVM, Logistic Regression)\n",
    "2. **Sentiment Classification** - Using all 3 models (Naive Bayes, SVM, Logistic Regression)\n",
    "\n",
    "**Features:**\n",
    "- Input: Tamil news headline\n",
    "- Output: Category & Sentiment predictions from ALL models\n",
    "- Shows model accuracies\n",
    "- Preprocessing pipeline included\n",
    "- Easy-to-use prediction function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce873cd",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67fca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тЬУ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"тЬУ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480fe6b",
   "metadata": {},
   "source": [
    "## 2. Tamil Text Preprocessing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9275eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тЬУ Loaded 127 stopwords\n",
      "тЬУ Loaded 133 suffixes\n",
      "\n",
      "тЬУ Preprocessor initialized\n"
     ]
    }
   ],
   "source": [
    "class TamilTextPreprocessor:\n",
    "    \"\"\"\n",
    "    Preprocessing pipeline for Tamil text (same as training preprocessing).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stopwords_file: str = 'resources/stopwords.txt', \n",
    "                 suffixes_file: str = 'resources/suffixes.csv'):\n",
    "        self.stopwords = set()\n",
    "        self.suffixes = {}\n",
    "        \n",
    "        # Load stopwords if available\n",
    "        if os.path.exists(stopwords_file):\n",
    "            with open(stopwords_file, 'r', encoding='utf-8') as f:\n",
    "                self.stopwords = {line.strip() for line in f if line.strip()}\n",
    "            print(f\"тЬУ Loaded {len(self.stopwords)} stopwords\")\n",
    "        else:\n",
    "            print(\"тЪа Stopwords file not found, continuing without stopwords\")\n",
    "        \n",
    "        # Load suffixes if available\n",
    "        if os.path.exists(suffixes_file):\n",
    "            try:\n",
    "                df = pd.read_csv(suffixes_file, encoding='utf-8')\n",
    "                for _, row in df.iterrows():\n",
    "                    suffix = str(row['suffix']).strip()\n",
    "                    if suffix:\n",
    "                        self.suffixes[suffix] = str(row['meaning']).strip()\n",
    "                self.sorted_suffixes = sorted(self.suffixes.keys(), key=len, reverse=True)\n",
    "                print(f\"тЬУ Loaded {len(self.suffixes)} suffixes\")\n",
    "            except:\n",
    "                print(\"тЪа Could not load suffixes, continuing without suffix removal\")\n",
    "        else:\n",
    "            print(\"тЪа Suffixes file not found, continuing without suffix removal\")\n",
    "    \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean Tamil text (remove English, digits, punctuation).\"\"\"\n",
    "        if pd.isna(text) or not text:\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text)\n",
    "        # Remove English letters\n",
    "        text = re.sub(r'[a-zA-Z]+', '', text)\n",
    "        # Remove digits\n",
    "        text = re.sub(r'[0-9рпж-рпп]+', '', text)\n",
    "        # Remove punctuation\n",
    "        text = re.sub(r'[!\\\"#$%&\\'()*+,\\-./:;<=>?@\\[\\\\\\\\\\]^_`{|}~тАжтАУтАФ]', ' ', text)\n",
    "        text = re.sub(r'[тВ╣$тВм┬г┬етЧПтЧЛтЦатЦбтШЕтШЖтЩжтЩетЩатЩг]', '', text)\n",
    "        # Normalize whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Tokenize text into words.\"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        return [w.strip() for w in text.split() if w.strip()]\n",
    "    \n",
    "    def remove_stopwords(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"Remove stopwords from token list.\"\"\"\n",
    "        if not self.stopwords:\n",
    "            return tokens\n",
    "        return [t for t in tokens if t not in self.stopwords]\n",
    "    \n",
    "    def remove_suffixes(self, word: str) -> str:\n",
    "        \"\"\"Remove Tamil suffixes from word.\"\"\"\n",
    "        if not self.suffixes:\n",
    "            return word\n",
    "        \n",
    "        for suffix in self.sorted_suffixes:\n",
    "            if word.endswith(suffix) and len(word) > len(suffix):\n",
    "                return word[:-len(suffix)]\n",
    "        return word\n",
    "    \n",
    "    def preprocess(self, text: str) -> str:\n",
    "        \"\"\"Complete preprocessing pipeline.\"\"\"\n",
    "        # Clean text\n",
    "        cleaned = self.clean_text(text)\n",
    "        # Tokenize\n",
    "        tokens = self.tokenize(cleaned)\n",
    "        # Remove stopwords\n",
    "        tokens = self.remove_stopwords(tokens)\n",
    "        # Remove suffixes\n",
    "        tokens = [self.remove_suffixes(t) for t in tokens]\n",
    "        # Join back\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = TamilTextPreprocessor()\n",
    "print(\"\\nтЬУ Preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e899e23",
   "metadata": {},
   "source": [
    "## 3. Load All Trained Models\n",
    "\n",
    "Loading:\n",
    "- **Category Models**: Naive Bayes, SVM, Logistic Regression\n",
    "- **Sentiment Models**: Naive Bayes, SVM, Logistic Regression\n",
    "- **Vectorizers**: Category and Sentiment TF-IDF vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b02af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all trained models...\n",
      "\n",
      "ЁЯУБ CATEGORY CLASSIFICATION MODELS:\n",
      "  тЬУ Naive Bayes loaded\n",
      "  тЬУ SVM loaded\n",
      "  тЬУ Logistic Regression loaded\n",
      "  тЬУ Category Vectorizer loaded\n",
      "\n",
      "ЁЯТн SENTIMENT CLASSIFICATION MODELS:\n",
      "  тЬУ Naive Bayes loaded\n",
      "  тЬУ SVM loaded\n",
      "  тЬУ Logistic Regression loaded\n",
      "  тЬУ Sentiment Vectorizer loaded\n",
      "\n",
      "============================================================\n",
      "MODEL LOADING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading all trained models...\\n\")\n",
    "\n",
    "# Dictionary to store all models and vectorizers\n",
    "models = {}\n",
    "\n",
    "# Load Category Models\n",
    "print(\"ЁЯУБ CATEGORY CLASSIFICATION MODELS:\")\n",
    "try:\n",
    "    with open('models/category_naive_bayes.pkl', 'rb') as f:\n",
    "        models['category_nb'] = pickle.load(f)\n",
    "    print(\"  тЬУ Naive Bayes loaded\")\n",
    "except:\n",
    "    print(\"  тЬЧ Naive Bayes not found\")\n",
    "    models['category_nb'] = None\n",
    "\n",
    "try:\n",
    "    with open('models/category_svm.pkl', 'rb') as f:\n",
    "        models['category_svm'] = pickle.load(f)\n",
    "    print(\"  тЬУ SVM loaded\")\n",
    "except:\n",
    "    print(\"  тЬЧ SVM not found\")\n",
    "    models['category_svm'] = None\n",
    "\n",
    "try:\n",
    "    with open('models/category_logistic.pkl', 'rb') as f:\n",
    "        models['category_lr'] = pickle.load(f)\n",
    "    print(\"  тЬУ Logistic Regression loaded\")\n",
    "except:\n",
    "    print(\"  тЬЧ Logistic Regression not found\")\n",
    "    models['category_lr'] = None\n",
    "\n",
    "# Load Category Vectorizer\n",
    "try:\n",
    "    with open('models/category_vectorizer.pkl', 'rb') as f:\n",
    "        category_vectorizer_data = pickle.load(f)\n",
    "    print(\"  тЬУ Category Vectorizer loaded\")\n",
    "    models['category_vectorizer'] = category_vectorizer_data\n",
    "except:\n",
    "    print(\"  тЬЧ Category Vectorizer not found\")\n",
    "    models['category_vectorizer'] = None\n",
    "\n",
    "# Load Sentiment Models\n",
    "print(\"\\nЁЯТн SENTIMENT CLASSIFICATION MODELS:\")\n",
    "try:\n",
    "    with open('models/sentiment_naive_bayes.pkl', 'rb') as f:\n",
    "        models['sentiment_nb'] = pickle.load(f)\n",
    "    print(\"  тЬУ Naive Bayes loaded\")\n",
    "except:\n",
    "    print(\"  тЬЧ Naive Bayes not found\")\n",
    "    models['sentiment_nb'] = None\n",
    "\n",
    "try:\n",
    "    with open('models/sentiment_svm.pkl', 'rb') as f:\n",
    "        models['sentiment_svm'] = pickle.load(f)\n",
    "    print(\"  тЬУ SVM loaded\")\n",
    "except:\n",
    "    print(\"  тЬЧ SVM not found\")\n",
    "    models['sentiment_svm'] = None\n",
    "\n",
    "try:\n",
    "    with open('models/sentiment_logistic.pkl', 'rb') as f:\n",
    "        models['sentiment_lr'] = pickle.load(f)\n",
    "    print(\"  тЬУ Logistic Regression loaded\")\n",
    "except:\n",
    "    print(\"  тЬЧ Logistic Regression not found\")\n",
    "    models['sentiment_lr'] = None\n",
    "\n",
    "# Load Sentiment Vectorizer\n",
    "try:\n",
    "    with open('models/sentiment_vectorizer.pkl', 'rb') as f:\n",
    "        sentiment_vectorizer_data = pickle.load(f)\n",
    "    print(\"  тЬУ Sentiment Vectorizer loaded\")\n",
    "    models['sentiment_vectorizer'] = sentiment_vectorizer_data\n",
    "except:\n",
    "    print(\"  тЬЧ Sentiment Vectorizer not found\")\n",
    "    models['sentiment_vectorizer'] = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL LOADING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39059dea",
   "metadata": {},
   "source": [
    "## 4. Load Model Accuracies from Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356ef66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model accuracies from reports...\n",
      "\n",
      "ЁЯУК CATEGORY MODEL ACCURACIES:\n",
      "  Naive Bayes     : Accuracy = 0.6455 (64.55%), F1 = 0.6390\n",
      "  SVM             : Accuracy = 0.6621 (66.21%), F1 = 0.6570\n",
      "  Logistic Reg.   : Accuracy = 0.6520 (65.20%), F1 = 0.6512\n",
      "\n",
      "ЁЯТн SENTIMENT MODEL ACCURACIES:\n",
      "  Naive Bayes     : Accuracy = 0.6525 (65.25%), F1 = 0.6507\n",
      "  SVM             : Accuracy = 0.6719 (67.19%), F1 = 0.6613\n",
      "  Logistic Reg.   : Accuracy = 0.6840 (68.40%), F1 = 0.6571\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dictionary to store model accuracies\n",
    "accuracies = {\n",
    "    'category': {},\n",
    "    'sentiment': {}\n",
    "}\n",
    "\n",
    "print(\"Loading model accuracies from reports...\\n\")\n",
    "\n",
    "# Load Category Model Accuracies\n",
    "print(\"ЁЯУК CATEGORY MODEL ACCURACIES:\")\n",
    "try:\n",
    "    with open('reports/category_naive_bayes_report.json', 'r') as f:\n",
    "        report = json.load(f)\n",
    "        acc = report['test_metrics']['accuracy']\n",
    "        f1 = report['test_metrics']['f1']\n",
    "        accuracies['category']['Naive Bayes'] = {'accuracy': acc, 'f1': f1}\n",
    "        print(f\"  Naive Bayes     : Accuracy = {acc:.4f} ({acc*100:.2f}%), F1 = {f1:.4f}\")\n",
    "except:\n",
    "    print(\"  Naive Bayes     : Report not found\")\n",
    "\n",
    "try:\n",
    "    with open('reports/category_svm_report.json', 'r') as f:\n",
    "        report = json.load(f)\n",
    "        acc = report['test_metrics']['accuracy']\n",
    "        f1 = report['test_metrics']['f1']\n",
    "        accuracies['category']['SVM'] = {'accuracy': acc, 'f1': f1}\n",
    "        print(f\"  SVM             : Accuracy = {acc:.4f} ({acc*100:.2f}%), F1 = {f1:.4f}\")\n",
    "except:\n",
    "    print(\"  SVM             : Report not found\")\n",
    "\n",
    "try:\n",
    "    with open('reports/category_logistic_report.json', 'r') as f:\n",
    "        report = json.load(f)\n",
    "        acc = report['test_metrics']['accuracy']\n",
    "        f1 = report['test_metrics']['f1']\n",
    "        accuracies['category']['Logistic Regression'] = {'accuracy': acc, 'f1': f1}\n",
    "        print(f\"  Logistic Reg.   : Accuracy = {acc:.4f} ({acc*100:.2f}%), F1 = {f1:.4f}\")\n",
    "except:\n",
    "    print(\"  Logistic Reg.   : Report not found\")\n",
    "\n",
    "# Load Sentiment Model Accuracies\n",
    "print(\"\\nЁЯТн SENTIMENT MODEL ACCURACIES:\")\n",
    "try:\n",
    "    with open('reports/sentiment_naive_bayes_report.json', 'r') as f:\n",
    "        report = json.load(f)\n",
    "        acc = report['test_metrics']['accuracy']\n",
    "        f1 = report['test_metrics']['f1']\n",
    "        accuracies['sentiment']['Naive Bayes'] = {'accuracy': acc, 'f1': f1}\n",
    "        print(f\"  Naive Bayes     : Accuracy = {acc:.4f} ({acc*100:.2f}%), F1 = {f1:.4f}\")\n",
    "except:\n",
    "    print(\"  Naive Bayes     : Report not found\")\n",
    "\n",
    "try:\n",
    "    with open('reports/sentiment_svm_report.json', 'r') as f:\n",
    "        report = json.load(f)\n",
    "        acc = report['test_metrics']['accuracy']\n",
    "        f1 = report['test_metrics']['f1']\n",
    "        accuracies['sentiment']['SVM'] = {'accuracy': acc, 'f1': f1}\n",
    "        print(f\"  SVM             : Accuracy = {acc:.4f} ({acc*100:.2f}%), F1 = {f1:.4f}\")\n",
    "except:\n",
    "    print(\"  SVM             : Report not found\")\n",
    "\n",
    "try:\n",
    "    with open('reports/sentiment_logistic_report.json', 'r') as f:\n",
    "        report = json.load(f)\n",
    "        acc = report['test_metrics']['accuracy']\n",
    "        f1 = report['test_metrics']['f1']\n",
    "        accuracies['sentiment']['Logistic Regression'] = {'accuracy': acc, 'f1': f1}\n",
    "        print(f\"  Logistic Reg.   : Accuracy = {acc:.4f} ({acc*100:.2f}%), F1 = {f1:.4f}\")\n",
    "except:\n",
    "    print(\"  Logistic Reg.   : Report not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5677e",
   "metadata": {},
   "source": [
    "## 5. TF-IDF Vectorization Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5fc43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тЬУ TF-IDF helper functions defined\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def compute_tf(tokens: List[str], vocabulary_set: set) -> Dict[str, float]:\n",
    "    \"\"\"Compute term frequency for tokens.\"\"\"\n",
    "    tf_dict = {}\n",
    "    if not tokens:\n",
    "        return tf_dict\n",
    "    \n",
    "    term_counts = Counter(tokens)\n",
    "    doc_length = len(tokens)\n",
    "    \n",
    "    for term, count in term_counts.items():\n",
    "        if term in vocabulary_set:\n",
    "            tf_dict[term] = count / doc_length\n",
    "    \n",
    "    return tf_dict\n",
    "\n",
    "def compute_tfidf(tf_dict: Dict[str, float], idf_dict: Dict[str, float]) -> Dict[str, float]:\n",
    "    \"\"\"Compute TF-IDF weights.\"\"\"\n",
    "    tfidf_dict = {}\n",
    "    for term, tf_value in tf_dict.items():\n",
    "        tfidf_dict[term] = tf_value * idf_dict.get(term, 0)\n",
    "    return tfidf_dict\n",
    "\n",
    "def create_tfidf_vector(tfidf_dict: Dict[str, float], word2idx: Dict[str, int], vocab_size: int):\n",
    "    \"\"\"Create sparse TF-IDF vector from TF-IDF dictionary.\"\"\"\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    \n",
    "    for term, tfidf_value in tfidf_dict.items():\n",
    "        if term in word2idx:\n",
    "            col.append(word2idx[term])\n",
    "            row.append(0)\n",
    "            data.append(tfidf_value)\n",
    "    \n",
    "    if not data:\n",
    "        # Return zero vector if no terms match\n",
    "        return csr_matrix((1, vocab_size), dtype=np.float32)\n",
    "    \n",
    "    return csr_matrix((data, (row, col)), shape=(1, vocab_size), dtype=np.float32)\n",
    "\n",
    "print(\"тЬУ TF-IDF helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c212437b",
   "metadata": {},
   "source": [
    "## 6. Main Prediction Function\n",
    "\n",
    "This function:\n",
    "1. Preprocesses the input Tamil headline\n",
    "2. Converts it to TF-IDF vectors (category & sentiment)\n",
    "3. Predicts using ALL available models\n",
    "4. Returns results with model accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f37459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тЬУ Prediction function defined\n"
     ]
    }
   ],
   "source": [
    "def predict_headline(headline: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Predict category and sentiment for a Tamil news headline using all models.\n",
    "    \n",
    "    Args:\n",
    "        headline: Tamil news headline text\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with predictions from all models and their accuracies\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"TAMIL NEWS HEADLINE PREDICTION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nЁЯУ░ Input Headline:\\n  {headline}\")\n",
    "    \n",
    "    # Step 1: Preprocess headline\n",
    "    print(\"\\nЁЯФз Preprocessing...\")\n",
    "    preprocessed = preprocessor.preprocess(headline)\n",
    "    print(f\"  Cleaned: {preprocessed}\")\n",
    "    \n",
    "    if not preprocessed.strip():\n",
    "        print(\"\\nтЪа Warning: Headline is empty after preprocessing!\")\n",
    "        return {'error': 'Empty headline after preprocessing'}\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = preprocessed.split()\n",
    "    print(f\"  Tokens: {tokens[:10]}...\" if len(tokens) > 10 else f\"  Tokens: {tokens}\")\n",
    "    \n",
    "    results = {\n",
    "        'original_headline': headline,\n",
    "        'preprocessed_headline': preprocessed,\n",
    "        'category_predictions': {},\n",
    "        'sentiment_predictions': {}\n",
    "    }\n",
    "    \n",
    "    # ============ CATEGORY CLASSIFICATION ============\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ЁЯУБ CATEGORY CLASSIFICATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if models['category_vectorizer'] is not None:\n",
    "        # Create TF-IDF vector for category\n",
    "        vocab = models['category_vectorizer']['vocabulary']\n",
    "        word2idx = models['category_vectorizer']['word2idx']\n",
    "        idf_dict = models['category_vectorizer']['idf_dict']\n",
    "        \n",
    "        vocab_set = set(vocab)\n",
    "        tf = compute_tf(tokens, vocab_set)\n",
    "        tfidf = compute_tfidf(tf, idf_dict)\n",
    "        X_category = create_tfidf_vector(tfidf, word2idx, len(vocab))\n",
    "        \n",
    "        # Predict with Naive Bayes\n",
    "        if models['category_nb'] is not None:\n",
    "            pred = models['category_nb'].predict(X_category)[0]\n",
    "            acc_info = accuracies['category'].get('Naive Bayes', {})\n",
    "            acc = acc_info.get('accuracy', 0)\n",
    "            f1 = acc_info.get('f1', 0)\n",
    "            results['category_predictions']['Naive Bayes'] = {\n",
    "                'prediction': pred,\n",
    "                'accuracy': f\"{acc:.4f} ({acc*100:.2f}%)\",\n",
    "                'f1_score': f\"{f1:.4f}\"\n",
    "            }\n",
    "            print(f\"\\n  ЁЯФ╣ Naive Bayes\")\n",
    "            print(f\"     Predicted Category: {pred}\")\n",
    "            print(f\"     Model Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "            print(f\"     F1-Score: {f1:.4f}\")\n",
    "        \n",
    "        # Predict with SVM\n",
    "        if models['category_svm'] is not None:\n",
    "            pred = models['category_svm'].predict(X_category)[0]\n",
    "            acc_info = accuracies['category'].get('SVM', {})\n",
    "            acc = acc_info.get('accuracy', 0)\n",
    "            f1 = acc_info.get('f1', 0)\n",
    "            results['category_predictions']['SVM'] = {\n",
    "                'prediction': pred,\n",
    "                'accuracy': f\"{acc:.4f} ({acc*100:.2f}%)\",\n",
    "                'f1_score': f\"{f1:.4f}\"\n",
    "            }\n",
    "            print(f\"\\n  ЁЯФ╣ Linear SVM\")\n",
    "            print(f\"     Predicted Category: {pred}\")\n",
    "            print(f\"     Model Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "            print(f\"     F1-Score: {f1:.4f}\")\n",
    "        \n",
    "        # Predict with Logistic Regression\n",
    "        if models['category_lr'] is not None:\n",
    "            pred = models['category_lr'].predict(X_category)[0]\n",
    "            acc_info = accuracies['category'].get('Logistic Regression', {})\n",
    "            acc = acc_info.get('accuracy', 0)\n",
    "            f1 = acc_info.get('f1', 0)\n",
    "            results['category_predictions']['Logistic Regression'] = {\n",
    "                'prediction': pred,\n",
    "                'accuracy': f\"{acc:.4f} ({acc*100:.2f}%)\",\n",
    "                'f1_score': f\"{f1:.4f}\"\n",
    "            }\n",
    "            print(f\"\\n  ЁЯФ╣ Logistic Regression\")\n",
    "            print(f\"     Predicted Category: {pred}\")\n",
    "            print(f\"     Model Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "            print(f\"     F1-Score: {f1:.4f}\")\n",
    "    else:\n",
    "        print(\"  тЬЧ Category vectorizer not available\")\n",
    "    \n",
    "    # ============ SENTIMENT CLASSIFICATION ============\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ЁЯТн SENTIMENT CLASSIFICATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if models['sentiment_vectorizer'] is not None:\n",
    "        # Create TF-IDF vector for sentiment\n",
    "        vocab = models['sentiment_vectorizer']['vocabulary']\n",
    "        word2idx = models['sentiment_vectorizer']['word2idx']\n",
    "        idf_dict = models['sentiment_vectorizer']['idf_dict']\n",
    "        \n",
    "        vocab_set = set(vocab)\n",
    "        tf = compute_tf(tokens, vocab_set)\n",
    "        tfidf = compute_tfidf(tf, idf_dict)\n",
    "        X_sentiment = create_tfidf_vector(tfidf, word2idx, len(vocab))\n",
    "        \n",
    "        # Predict with Naive Bayes\n",
    "        if models['sentiment_nb'] is not None:\n",
    "            pred = models['sentiment_nb'].predict(X_sentiment)[0]\n",
    "            acc_info = accuracies['sentiment'].get('Naive Bayes', {})\n",
    "            acc = acc_info.get('accuracy', 0)\n",
    "            f1 = acc_info.get('f1', 0)\n",
    "            results['sentiment_predictions']['Naive Bayes'] = {\n",
    "                'prediction': pred,\n",
    "                'accuracy': f\"{acc:.4f} ({acc*100:.2f}%)\",\n",
    "                'f1_score': f\"{f1:.4f}\"\n",
    "            }\n",
    "            print(f\"\\n  ЁЯФ╣ Naive Bayes\")\n",
    "            print(f\"     Predicted Sentiment: {pred}\")\n",
    "            print(f\"     Model Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "            print(f\"     F1-Score: {f1:.4f}\")\n",
    "        \n",
    "        # Predict with SVM\n",
    "        if models['sentiment_svm'] is not None:\n",
    "            pred = models['sentiment_svm'].predict(X_sentiment)[0]\n",
    "            acc_info = accuracies['sentiment'].get('SVM', {})\n",
    "            acc = acc_info.get('accuracy', 0)\n",
    "            f1 = acc_info.get('f1', 0)\n",
    "            results['sentiment_predictions']['SVM'] = {\n",
    "                'prediction': pred,\n",
    "                'accuracy': f\"{acc:.4f} ({acc*100:.2f}%)\",\n",
    "                'f1_score': f\"{f1:.4f}\"\n",
    "            }\n",
    "            print(f\"\\n  ЁЯФ╣ Linear SVM\")\n",
    "            print(f\"     Predicted Sentiment: {pred}\")\n",
    "            print(f\"     Model Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "            print(f\"     F1-Score: {f1:.4f}\")\n",
    "        \n",
    "        # Predict with Logistic Regression\n",
    "        if models['sentiment_lr'] is not None:\n",
    "            pred = models['sentiment_lr'].predict(X_sentiment)[0]\n",
    "            acc_info = accuracies['sentiment'].get('Logistic Regression', {})\n",
    "            acc = acc_info.get('accuracy', 0)\n",
    "            f1 = acc_info.get('f1', 0)\n",
    "            results['sentiment_predictions']['Logistic Regression'] = {\n",
    "                'prediction': pred,\n",
    "                'accuracy': f\"{acc:.4f} ({acc*100:.2f}%)\",\n",
    "                'f1_score': f\"{f1:.4f}\"\n",
    "            }\n",
    "            print(f\"\\n  ЁЯФ╣ Logistic Regression\")\n",
    "            print(f\"     Predicted Sentiment: {pred}\")\n",
    "            print(f\"     Model Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "            print(f\"     F1-Score: {f1:.4f}\")\n",
    "    else:\n",
    "        print(\"  тЬЧ Sentiment vectorizer not available\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREDICTION COMPLETE\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"тЬУ Prediction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa4f36e",
   "metadata": {},
   "source": [
    "## 7. Test with Sample Headlines\n",
    "\n",
    "Let's test the prediction system with some sample Tamil news headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee3d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with sample headlines...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample Tamil headlines for testing\n",
    "sample_headlines = [\n",
    "    \"роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ\",\n",
    "    \"рокрпБродро┐роп родрпКро┤ро┐ро▓рпНроирпБроЯрпНрок роХрогрпНроЯрпБрокро┐роЯро┐рокрпНрокрпБ роЕро▒ро┐ро╡ро┐ропро▓рпН роЙро▓роХро┐ро▓рпН роЪро╛родройрпИ\",\n",
    "    \"роЕро░роЪрпБ рокрпБродро┐роп роХро▓рпНро╡ро┐ роХрпКро│рпНроХрпИ роЕро▒ро┐ро╡ро┐рокрпНрокрпБ роЪрпЖропрпНродродрпБ\",\n",
    "    \"роЗро▓роЩрпНроХрпИ роЕро░роЪрпБ рокрпБродро┐роп рокрпКро░рпБро│ро╛родро╛ро░ роЪрпАро░рпНродро┐ро░рпБродрпНродроЩрпНроХро│рпИ роЕро▒ро┐ро╡ро┐родрпНродродрпБ\",\n",
    "    \"роЪрпЖройрпНройрпИ рооро╛роироХро░ро┐ро▓рпН рокрпБродро┐роп роорпЖроЯрпНро░рпЛ ро░ропро┐ро▓рпН родро┐роЯрпНроЯроорпН родрпКроЯроЩрпНроХро┐ропродрпБ\"\n",
    "]\n",
    "\n",
    "print(\"Testing with sample headlines...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ff3d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAMIL NEWS HEADLINE PREDICTION\n",
      "================================================================================\n",
      "\n",
      "ЁЯУ░ Input Headline:\n",
      "  роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ\n",
      "\n",
      "ЁЯФз Preprocessing...\n",
      "  Cleaned: роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ\n",
      "  Tokens: ['роЗроирпНродро┐роп', 'роХро┐ро░ро┐роХрпНроХрпЖроЯрпН', 'роЕрогро┐', 'роЙро▓роХроХрпН', 'роХрпЛрокрпНрокрпИропрпИ', 'ро╡рпЖройрпНро▒родрпБ']\n",
      "\n",
      "================================================================================\n",
      "ЁЯУБ CATEGORY CLASSIFICATION\n",
      "================================================================================\n",
      "\n",
      "  ЁЯФ╣ Naive Bayes\n",
      "     Predicted Category: sports\n",
      "     Model Accuracy: 0.6455 (64.55%)\n",
      "     F1-Score: 0.6390\n",
      "\n",
      "  ЁЯФ╣ Linear SVM\n",
      "     Predicted Category: sports\n",
      "     Model Accuracy: 0.6621 (66.21%)\n",
      "     F1-Score: 0.6570\n",
      "\n",
      "  ЁЯФ╣ Logistic Regression\n",
      "     Predicted Category: sports\n",
      "     Model Accuracy: 0.6520 (65.20%)\n",
      "     F1-Score: 0.6512\n",
      "\n",
      "================================================================================\n",
      "ЁЯТн SENTIMENT CLASSIFICATION\n",
      "================================================================================\n",
      "\n",
      "  ЁЯФ╣ Naive Bayes\n",
      "     Predicted Sentiment: Positive\n",
      "     Model Accuracy: 0.6525 (65.25%)\n",
      "     F1-Score: 0.6507\n",
      "\n",
      "  ЁЯФ╣ Linear SVM\n",
      "     Predicted Sentiment: Positive\n",
      "     Model Accuracy: 0.6719 (67.19%)\n",
      "     F1-Score: 0.6613\n",
      "\n",
      "  ЁЯФ╣ Logistic Regression\n",
      "     Predicted Sentiment: Positive\n",
      "     Model Accuracy: 0.6840 (68.40%)\n",
      "     F1-Score: 0.6571\n",
      "\n",
      "================================================================================\n",
      "PREDICTION COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with first sample headline\n",
    "if sample_headlines:\n",
    "    result = predict_headline(sample_headlines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05ad49",
   "metadata": {},
   "source": [
    "## 8. Interactive Prediction Cell\n",
    "\n",
    "**Enter your own Tamil headline below and run the cell to get predictions!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74cbc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TAMIL NEWS HEADLINE PREDICTION\n",
      "================================================================================\n",
      "\n",
      "ЁЯУ░ Input Headline:\n",
      "  роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ\n",
      "\n",
      "ЁЯФз Preprocessing...\n",
      "  Cleaned: роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ\n",
      "  Tokens: ['роЗроирпНродро┐роп', 'роХро┐ро░ро┐роХрпНроХрпЖроЯрпН', 'роЕрогро┐', 'роЙро▓роХроХрпН', 'роХрпЛрокрпНрокрпИропрпИ', 'ро╡рпЖройрпНро▒родрпБ']\n",
      "\n",
      "================================================================================\n",
      "ЁЯУБ CATEGORY CLASSIFICATION\n",
      "================================================================================\n",
      "\n",
      "  ЁЯФ╣ Naive Bayes\n",
      "     Predicted Category: sports\n",
      "     Model Accuracy: 0.6455 (64.55%)\n",
      "     F1-Score: 0.6390\n",
      "\n",
      "  ЁЯФ╣ Linear SVM\n",
      "     Predicted Category: sports\n",
      "     Model Accuracy: 0.6621 (66.21%)\n",
      "     F1-Score: 0.6570\n",
      "\n",
      "  ЁЯФ╣ Logistic Regression\n",
      "     Predicted Category: sports\n",
      "     Model Accuracy: 0.6520 (65.20%)\n",
      "     F1-Score: 0.6512\n",
      "\n",
      "================================================================================\n",
      "ЁЯТн SENTIMENT CLASSIFICATION\n",
      "================================================================================\n",
      "\n",
      "  ЁЯФ╣ Naive Bayes\n",
      "     Predicted Sentiment: Positive\n",
      "     Model Accuracy: 0.6525 (65.25%)\n",
      "     F1-Score: 0.6507\n",
      "\n",
      "  ЁЯФ╣ Linear SVM\n",
      "     Predicted Sentiment: Positive\n",
      "     Model Accuracy: 0.6719 (67.19%)\n",
      "     F1-Score: 0.6613\n",
      "\n",
      "  ЁЯФ╣ Logistic Regression\n",
      "     Predicted Sentiment: Positive\n",
      "     Model Accuracy: 0.6840 (68.40%)\n",
      "     F1-Score: 0.6571\n",
      "\n",
      "================================================================================\n",
      "PREDICTION COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enter your Tamil headline here\n",
    "your_headline = \"роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ\"\n",
    "\n",
    "# Get predictions\n",
    "result = predict_headline(your_headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059443b4",
   "metadata": {},
   "source": [
    "## 9. Batch Prediction Function\n",
    "\n",
    "Predict multiple headlines at once and save results to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e848d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тЬУ Batch prediction function defined\n"
     ]
    }
   ],
   "source": [
    "def predict_batch(headlines: List[str], save_to_csv: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict category and sentiment for multiple headlines.\n",
    "    \n",
    "    Args:\n",
    "        headlines: List of Tamil news headlines\n",
    "        save_to_csv: Whether to save results to CSV file\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions from all models\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing {len(headlines)} headlines...\\n\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    for i, headline in enumerate(headlines, 1):\n",
    "        print(f\"[{i}/{len(headlines)}] Processing: {headline[:50]}...\")\n",
    "        \n",
    "        # Preprocess\n",
    "        preprocessed = preprocessor.preprocess(headline)\n",
    "        \n",
    "        if not preprocessed.strip():\n",
    "            print(f\"  тЪа Skipping empty headline\")\n",
    "            continue\n",
    "        \n",
    "        tokens = preprocessed.split()\n",
    "        \n",
    "        row = {\n",
    "            'original_headline': headline,\n",
    "            'preprocessed_headline': preprocessed\n",
    "        }\n",
    "        \n",
    "        # Category predictions\n",
    "        if models['category_vectorizer'] is not None:\n",
    "            vocab = models['category_vectorizer']['vocabulary']\n",
    "            word2idx = models['category_vectorizer']['word2idx']\n",
    "            idf_dict = models['category_vectorizer']['idf_dict']\n",
    "            vocab_set = set(vocab)\n",
    "            \n",
    "            tf = compute_tf(tokens, vocab_set)\n",
    "            tfidf = compute_tfidf(tf, idf_dict)\n",
    "            X = create_tfidf_vector(tfidf, word2idx, len(vocab))\n",
    "            \n",
    "            if models['category_nb'] is not None:\n",
    "                row['category_nb'] = models['category_nb'].predict(X)[0]\n",
    "            if models['category_svm'] is not None:\n",
    "                row['category_svm'] = models['category_svm'].predict(X)[0]\n",
    "            if models['category_lr'] is not None:\n",
    "                row['category_lr'] = models['category_lr'].predict(X)[0]\n",
    "        \n",
    "        # Sentiment predictions\n",
    "        if models['sentiment_vectorizer'] is not None:\n",
    "            vocab = models['sentiment_vectorizer']['vocabulary']\n",
    "            word2idx = models['sentiment_vectorizer']['word2idx']\n",
    "            idf_dict = models['sentiment_vectorizer']['idf_dict']\n",
    "            vocab_set = set(vocab)\n",
    "            \n",
    "            tf = compute_tf(tokens, vocab_set)\n",
    "            tfidf = compute_tfidf(tf, idf_dict)\n",
    "            X = create_tfidf_vector(tfidf, word2idx, len(vocab))\n",
    "            \n",
    "            if models['sentiment_nb'] is not None:\n",
    "                row['sentiment_nb'] = models['sentiment_nb'].predict(X)[0]\n",
    "            if models['sentiment_svm'] is not None:\n",
    "                row['sentiment_svm'] = models['sentiment_svm'].predict(X)[0]\n",
    "            if models['sentiment_lr'] is not None:\n",
    "                row['sentiment_lr'] = models['sentiment_lr'].predict(X)[0]\n",
    "        \n",
    "        results_list.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Save to CSV if requested\n",
    "    if save_to_csv:\n",
    "        output_file = 'output/batch_predictions.csv'\n",
    "        df_results.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nтЬУ Results saved to: {output_file}\")\n",
    "    \n",
    "    print(f\"\\nтЬУ Batch prediction complete: {len(df_results)} headlines processed\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "print(\"тЬУ Batch prediction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6485077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 5 headlines...\n",
      "\n",
      "[1/5] Processing: роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ...\n",
      "[2/5] Processing: рокрпБродро┐роп родрпКро┤ро┐ро▓рпНроирпБроЯрпНрок роХрогрпНроЯрпБрокро┐роЯро┐рокрпНрокрпБ роЕро▒ро┐ро╡ро┐ропро▓рпН роЙро▓роХро┐ро▓рпН роЪро╛...\n",
      "[3/5] Processing: роЕро░роЪрпБ рокрпБродро┐роп роХро▓рпНро╡ро┐ роХрпКро│рпНроХрпИ роЕро▒ро┐ро╡ро┐рокрпНрокрпБ роЪрпЖропрпНродродрпБ...\n",
      "[4/5] Processing: роЗро▓роЩрпНроХрпИ роЕро░роЪрпБ рокрпБродро┐роп рокрпКро░рпБро│ро╛родро╛ро░ роЪрпАро░рпНродро┐ро░рпБродрпНродроЩрпНроХро│рпИ роЕро▒ро┐ро╡ро┐...\n",
      "[5/5] Processing: роЪрпЖройрпНройрпИ рооро╛роироХро░ро┐ро▓рпН рокрпБродро┐роп роорпЖроЯрпНро░рпЛ ро░ропро┐ро▓рпН родро┐роЯрпНроЯроорпН родрпКроЯроЩрпНроХро┐...\n",
      "\n",
      "тЬУ Results saved to: output/batch_predictions.csv\n",
      "\n",
      "тЬУ Batch prediction complete: 5 headlines processed\n",
      "\n",
      "================================================================================\n",
      "BATCH PREDICTION RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_headline</th>\n",
       "      <th>preprocessed_headline</th>\n",
       "      <th>category_nb</th>\n",
       "      <th>category_svm</th>\n",
       "      <th>category_lr</th>\n",
       "      <th>sentiment_nb</th>\n",
       "      <th>sentiment_svm</th>\n",
       "      <th>sentiment_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ</td>\n",
       "      <td>роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "      <td>sports</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>рокрпБродро┐роп родрпКро┤ро┐ро▓рпНроирпБроЯрпНрок роХрогрпНроЯрпБрокро┐роЯро┐рокрпНрокрпБ роЕро▒ро┐ро╡ро┐ропро▓рпН роЙро▓роХро┐ро▓...</td>\n",
       "      <td>рокрпБродро┐роп родрпКро┤ро┐ро▓рпНроирпБроЯрпНрок роХрогрпНроЯрпБрокро┐роЯро┐рокрпНрокрпБ роЕро▒ро┐ро╡ро┐ропро▓рпН роЙро▓роХро┐ро▓...</td>\n",
       "      <td>technology</td>\n",
       "      <td>technology</td>\n",
       "      <td>technology</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>роЕро░роЪрпБ рокрпБродро┐роп роХро▓рпНро╡ро┐ роХрпКро│рпНроХрпИ роЕро▒ро┐ро╡ро┐рокрпНрокрпБ роЪрпЖропрпНродродрпБ</td>\n",
       "      <td>роЕро░роЪрпБ рокрпБродро┐роп роХро▓рпНро╡ро┐ роХрпКро│рпНроХрпИ роЕро▒ро┐ро╡ро┐рокрпНрокрпБ роЪрпЖропрпНродродрпБ</td>\n",
       "      <td>tamilnadu</td>\n",
       "      <td>technology</td>\n",
       "      <td>technology</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>роЗро▓роЩрпНроХрпИ роЕро░роЪрпБ рокрпБродро┐роп рокрпКро░рпБро│ро╛родро╛ро░ роЪрпАро░рпНродро┐ро░рпБродрпНродроЩрпНроХро│рпИ роЕ...</td>\n",
       "      <td>роЗро▓роЩрпНроХрпИ роЕро░роЪрпБ рокрпБродро┐роп рокрпКро░рпБро│ро╛родро╛ро░ роЪрпАро░рпНродро┐ро░рпБродрпНродроЩрпН роЕро▒ро┐ро╡ро┐</td>\n",
       "      <td>india</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>роЪрпЖройрпНройрпИ рооро╛роироХро░ро┐ро▓рпН рокрпБродро┐роп роорпЖроЯрпНро░рпЛ ро░ропро┐ро▓рпН родро┐роЯрпНроЯроорпН родрпКроЯ...</td>\n",
       "      <td>роЪрпЖройрпНройрпИ рооро╛роироХро░ро┐ро▓рпН рокрпБродро┐роп роорпЖроЯрпНро░рпЛ ро░ропро┐ро▓рпН родро┐роЯрпНроЯроорпН родрпКроЯ...</td>\n",
       "      <td>tamilnadu</td>\n",
       "      <td>tamilnadu</td>\n",
       "      <td>tamilnadu</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_headline  \\\n",
       "0       роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ   \n",
       "1  рокрпБродро┐роп родрпКро┤ро┐ро▓рпНроирпБроЯрпНрок роХрогрпНроЯрпБрокро┐роЯро┐рокрпНрокрпБ роЕро▒ро┐ро╡ро┐ропро▓рпН роЙро▓роХро┐ро▓...   \n",
       "2          роЕро░роЪрпБ рокрпБродро┐роп роХро▓рпНро╡ро┐ роХрпКро│рпНроХрпИ роЕро▒ро┐ро╡ро┐рокрпНрокрпБ роЪрпЖропрпНродродрпБ   \n",
       "3  роЗро▓роЩрпНроХрпИ роЕро░роЪрпБ рокрпБродро┐роп рокрпКро░рпБро│ро╛родро╛ро░ роЪрпАро░рпНродро┐ро░рпБродрпНродроЩрпНроХро│рпИ роЕ...   \n",
       "4  роЪрпЖройрпНройрпИ рооро╛роироХро░ро┐ро▓рпН рокрпБродро┐роп роорпЖроЯрпНро░рпЛ ро░ропро┐ро▓рпН родро┐роЯрпНроЯроорпН родрпКроЯ...   \n",
       "\n",
       "                               preprocessed_headline category_nb category_svm  \\\n",
       "0       роЗроирпНродро┐роп роХро┐ро░ро┐роХрпНроХрпЖроЯрпН роЕрогро┐ роЙро▓роХроХрпН роХрпЛрокрпНрокрпИропрпИ ро╡рпЖройрпНро▒родрпБ      sports       sports   \n",
       "1  рокрпБродро┐роп родрпКро┤ро┐ро▓рпНроирпБроЯрпНрок роХрогрпНроЯрпБрокро┐роЯро┐рокрпНрокрпБ роЕро▒ро┐ро╡ро┐ропро▓рпН роЙро▓роХро┐ро▓...  technology   technology   \n",
       "2          роЕро░роЪрпБ рокрпБродро┐роп роХро▓рпНро╡ро┐ роХрпКро│рпНроХрпИ роЕро▒ро┐ро╡ро┐рокрпНрокрпБ роЪрпЖропрпНродродрпБ   tamilnadu   technology   \n",
       "3    роЗро▓роЩрпНроХрпИ роЕро░роЪрпБ рокрпБродро┐роп рокрпКро░рпБро│ро╛родро╛ро░ роЪрпАро░рпНродро┐ро░рпБродрпНродроЩрпН роЕро▒ро┐ро╡ро┐       india        world   \n",
       "4  роЪрпЖройрпНройрпИ рооро╛роироХро░ро┐ро▓рпН рокрпБродро┐роп роорпЖроЯрпНро░рпЛ ро░ропро┐ро▓рпН родро┐роЯрпНроЯроорпН родрпКроЯ...   tamilnadu    tamilnadu   \n",
       "\n",
       "  category_lr sentiment_nb sentiment_svm sentiment_lr  \n",
       "0      sports     Positive      Positive     Positive  \n",
       "1  technology     Positive      Positive     Positive  \n",
       "2  technology      Neutral       Neutral      Neutral  \n",
       "3       world      Neutral       Neutral      Neutral  \n",
       "4   tamilnadu      Neutral       Neutral      Neutral  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test batch prediction with sample headlines\n",
    "if sample_headlines:\n",
    "    batch_results = predict_batch(sample_headlines, save_to_csv=True)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BATCH PREDICTION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    display(batch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bcc8f3",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9890067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PREDICTION SYSTEM SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ЁЯУК LOADED MODELS:\n",
      "  Category Classification:\n",
      "    - Naive Bayes:        тЬУ\n",
      "    - SVM:                тЬУ\n",
      "    - Logistic Regression: тЬУ\n",
      "    - Vectorizer:         тЬУ\n",
      "\n",
      "  Sentiment Classification:\n",
      "    - Naive Bayes:        тЬУ\n",
      "    - SVM:                тЬУ\n",
      "    - Logistic Regression: тЬУ\n",
      "    - Vectorizer:         тЬУ\n",
      "\n",
      "ЁЯУИ MODEL PERFORMANCE:\n",
      "  Category Models:\n",
      "    Naive Bayes         : 64.55% accuracy, F1=0.6390\n",
      "    SVM                 : 66.21% accuracy, F1=0.6570\n",
      "    Logistic Regression : 65.20% accuracy, F1=0.6512\n",
      "\n",
      "  Sentiment Models:\n",
      "    Naive Bayes         : 65.25% accuracy, F1=0.6507\n",
      "    SVM                 : 67.19% accuracy, F1=0.6613\n",
      "    Logistic Regression : 68.40% accuracy, F1=0.6571\n",
      "\n",
      "================================================================================\n",
      "тЬЕ SYSTEM READY FOR PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "Usage:\n",
      "  1. Single prediction: predict_headline('your tamil headline here')\n",
      "  2. Batch prediction:  predict_batch([headline1, headline2, ...])\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTION SYSTEM SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nЁЯУК LOADED MODELS:\")\n",
    "print(\"  Category Classification:\")\n",
    "print(f\"    - Naive Bayes:        {'тЬУ' if models['category_nb'] else 'тЬЧ'}\")\n",
    "print(f\"    - SVM:                {'тЬУ' if models['category_svm'] else 'тЬЧ'}\")\n",
    "print(f\"    - Logistic Regression: {'тЬУ' if models['category_lr'] else 'тЬЧ'}\")\n",
    "print(f\"    - Vectorizer:         {'тЬУ' if models['category_vectorizer'] else 'тЬЧ'}\")\n",
    "\n",
    "print(\"\\n  Sentiment Classification:\")\n",
    "print(f\"    - Naive Bayes:        {'тЬУ' if models['sentiment_nb'] else 'тЬЧ'}\")\n",
    "print(f\"    - SVM:                {'тЬУ' if models['sentiment_svm'] else 'тЬЧ'}\")\n",
    "print(f\"    - Logistic Regression: {'тЬУ' if models['sentiment_lr'] else 'тЬЧ'}\")\n",
    "print(f\"    - Vectorizer:         {'тЬУ' if models['sentiment_vectorizer'] else 'тЬЧ'}\")\n",
    "\n",
    "print(\"\\nЁЯУИ MODEL PERFORMANCE:\")\n",
    "print(\"  Category Models:\")\n",
    "for model_name, metrics in accuracies['category'].items():\n",
    "    print(f\"    {model_name:20s}: {metrics['accuracy']:.2%} accuracy, F1={metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\n  Sentiment Models:\")\n",
    "for model_name, metrics in accuracies['sentiment'].items():\n",
    "    print(f\"    {model_name:20s}: {metrics['accuracy']:.2%} accuracy, F1={metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"тЬЕ SYSTEM READY FOR PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  1. Single prediction: predict_headline('your tamil headline here')\")\n",
    "print(\"  2. Batch prediction:  predict_batch([headline1, headline2, ...])\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
